{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 変数定義\n",
    "\n",
    "4 seasons * 7 bandsのデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# define vars ---------------------------------------------\n",
    "under = 90\n",
    "gpu_list = ['/gpu:0', '/gpu:1']\n",
    "SEED = 31\n",
    "DEM = True\n",
    "\n",
    "# 共通params ---------------------------------------------------\n",
    "n_trials  = 2**2          # ベイズ最適化回数\n",
    "outer_cvs = 2\n",
    "inner_cvs = 2\n",
    "\n",
    "# CNN Training params ------------------------------------------\n",
    "train_epochs = 2**2      # エポック数\n",
    "best_epochs = 2**5       # 最終モデル決定用のエポック数\n",
    "early_stopping = 2**3    # \n",
    "\n",
    "# LightGBM params -----------------------------------------------\n",
    "lgb_boosting_type = 'gbdt'\n",
    "\n",
    "import os, zipfile, io, re\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "# Utils -----------------------\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "import random\n",
    "import pickle\n",
    "import datetime\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import ipynb_path\n",
    "from math import sqrt\n",
    "import tifffile\n",
    "# Machine Learning ---------------\n",
    "import lightgbm as LGB\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "from optuna import integration\n",
    "import optuna\n",
    "import optuna.integration.lightgbm as lgb\n",
    "# Keras, TensorFlow ---------------\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, GlobalAveragePooling2D, AveragePooling2D, MaxPooling2D, BatchNormalization, Convolution2D, Input\n",
    "from keras import optimizers\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "warnings.filterwarnings('ignore')\n",
    "SEED = 31\n",
    "np.random.seed(SEED)\n",
    "gpus = len(gpu_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     1,
     5,
     10,
     14,
     60,
     78,
     128,
     129,
     174,
     192,
     241,
     322,
     348,
     361,
     372,
     387,
     393,
     405,
     415,
     426,
     441
    ]
   },
   "outputs": [],
   "source": [
    "# define functions\n",
    "def pkl_saver(object, pkl_filename):\n",
    "    with open(pkl_filename, 'wb') as web:\n",
    "        pickle.dump(object , web)\n",
    "\n",
    "def pkl_loader(pkl_filename):\n",
    "    with open(pkl_filename, 'rb') as web:\n",
    "        data = pickle.load(web)\n",
    "    return data\n",
    "\n",
    "def dir_generator(dir_path):\n",
    "    if os.path.exists(dir_path) == False:\n",
    "        os.mkdir(dir_path)\n",
    "\n",
    "def train_import():\n",
    "    if os.path.exists(data_path + f'df_{N}x{N}.pkl'):\n",
    "        df = pkl_loader(data_path + f'df_{N}x{N}.pkl')\n",
    "    else:\n",
    "        trial = int(len(imgfiles)/28)\n",
    "        X = [] # X: 説明変数 = (N*N)*(7*4)のデータ\n",
    "        Y = [] # Y: 目的変数\n",
    "        point = [] # point: 緯度経度\n",
    "        X_28 = []\n",
    "        Y_28 = 0\n",
    "        point_28 = []\n",
    "        filenames = []\n",
    "        max_light = 0\n",
    "        print('inputdata_processing...')\n",
    "\n",
    "        for box in tqdm(range(trial)):\n",
    "            for imgfile in imgfiles[box*28: (box+1)*28]:\n",
    "                # ZIPから画像読み込み\n",
    "                image = tifffile.imread(imgfile)\n",
    "        #         print(image.shape)\n",
    "                file = os.path.basename(imgfile)\n",
    "                file_split = [i for i in file.split('_')]\n",
    "                X_28.append(image)\n",
    "            Y_28 = file_split[5].split(\".\")[0]\n",
    "            point_28 = [float(file_split[1]), float(file_split[2])]\n",
    "            filenames.append(f\"{file_split[0]}_{file_split[1]}_{file_split[2]}_{Y_28}\")\n",
    "            X.append(X_28[box*28: (box+1)*28])\n",
    "            Y.append(Y_28)\n",
    "            point.append(point_28)\n",
    "        del X_28, Y_28, point_28\n",
    "        X = np.asarray(X)\n",
    "        print(X.shape)\n",
    "        X = X.transpose(0,2,3,1)\n",
    "        print(X.shape)\n",
    "        Y = np.array(Y)\n",
    "        filenames = np.array(filenames)\n",
    "        point = np.array(point)\n",
    "        region = KMeans(n_clusters = outer_cvs, random_state=SEED).fit(point).labels_\n",
    "        # label encorder===========================================\n",
    "        labels = ['Water', 'Urban and built-up', 'Rice paddy',  'Crops', 'Grassland', 'DBF', 'DNF', 'EBF', 'ENF', 'Bare land' ]\n",
    "        for i in range(len(labels)):\n",
    "            Y[Y==labels[i]] = int(i)\n",
    "        df = [filenames, X, Y, point, region]\n",
    "        pkl_saver(df, os.path.join(data_path, f'df_{N}x{N}.pkl'))\n",
    "        \n",
    "    return df[0], df[1], df[2], df[3], df[4]\n",
    "def train_transform():\n",
    "    if os.path.exists(data_path + f'df_{N}x{N}_{standarization[standarization_num]}.pkl'):\n",
    "        df_train = pkl_loader(data_path + f'df_{N}x{N}_{standarization[standarization_num]}.pkl')\n",
    "        print(\"train_df をインポートしたよ！\")\n",
    "    else:\n",
    "        print(\"pklを新しく作成中ですが，標準化・正規化のコードに書き直しましたか？\")\n",
    "        X_train_zeros = np.zeros((X_train.shape[0], N*N*28))\n",
    "        for i in range(len(X_train)):\n",
    "            for k in range(N):\n",
    "                for l in range(N):\n",
    "                    for j in range(28):\n",
    "                        X_train_zeros[i][j+k+l] = X_train[i][k][l][j]\n",
    "        # X_train の名前が重複していたので違う名前に変えた. X_train_tmp\n",
    "        X_train_tmp = X_train_zeros\n",
    "        df_train = pd.concat([make_df(Y_train), make_df(X_train_tmp)], axis=1)\n",
    "        pkl_saver(df_train, os.path.join(data_path, f'df_{N}x{N}_{standarization[standarization_num]}.pkl'))\n",
    "        \n",
    "    return df_train.iloc[:, 1:], make_df(Y_train)\n",
    "def train_dem_import():\n",
    "    if os.path.exists(data_path + f'df_{N}x{N}_dem.pkl'):\n",
    "        df = pkl_loader(data_path + f'df_{N}x{N}_dem.pkl')\n",
    "    else:\n",
    "        trial = int(len(imgfiles)/28)\n",
    "        X = [] # X: 説明変数 = (N*N)*(7*4)のデータ\n",
    "        Y = [] # Y: 目的変数\n",
    "        point = [] # point: 緯度経度\n",
    "        X_28 = []\n",
    "        Y_28 = 0\n",
    "        point_28 = []\n",
    "        filenames = []\n",
    "        max_light = 0\n",
    "        print('inputdata_processing...')\n",
    "\n",
    "        for box in tqdm(range(trial)):\n",
    "            for imgfile in imgfiles[box*28: (box+1)*28]:\n",
    "                # ZIPから画像読み込み\n",
    "                image = tifffile.imread(imgfile)[0][0]\n",
    "        #         print(image.shape)\n",
    "                file = os.path.basename(imgfile)\n",
    "                file_split = [i for i in file.split('_')]\n",
    "                X_28.append(image)\n",
    "            dem_data = tifffile.imread(train_dem_files[box])[0][0]\n",
    "            X_28.append(dem_data)\n",
    "            Y_28 = file_split[5].split(\".\")[0]\n",
    "            point_28 = [float(file_split[1]), float(file_split[2])]\n",
    "            filenames.append(f\"{file_split[0]}_{file_split[1]}_{file_split[2]}_{Y_28}\")\n",
    "            X.append(X_28[box*29: (box+1)*29])\n",
    "            Y.append(Y_28)\n",
    "            point.append(point_28)\n",
    "    #         if box==100:break\n",
    "        del X_28, Y_28, point_28\n",
    "        X = np.asarray(X)\n",
    "        print(X.shape)\n",
    "    #     X = X.transpose(0,2,3,1)\n",
    "        print(X.shape)\n",
    "        Y = np.array(Y)\n",
    "        filenames = np.array(filenames)\n",
    "        point = np.array(point)\n",
    "        region = KMeans(n_clusters = outer_cvs, random_state=SEED).fit(point).labels_\n",
    "        # label encorder===========================================\n",
    "        labels = ['Water', 'Urban and built-up', 'Rice paddy',  'Crops', 'Grassland', 'DBF', 'DNF', 'EBF', 'ENF', 'Bare land' ]\n",
    "        for i in range(len(labels)):\n",
    "            Y[Y==labels[i]] = int(i)\n",
    "        df = [filenames, X, Y, point, region]\n",
    "        pkl_saver(df, os.path.join(data_path, f'df_{N}x{N}_dem.pkl'))\n",
    "    \n",
    "    return df[0], df[1], df[2], df[3], df[4]\n",
    "        \n",
    "def test_import():\n",
    "    if os.path.exists(data_path + f'df_{N}x{N}_testset.pkl'):\n",
    "        df = pkl_loader(data_path + f'df_{N}x{N}_testset.pkl')\n",
    "    else:\n",
    "        trial = int(len(testfiles)/28)\n",
    "    #     trial = 100\n",
    "        X = [] # X: 説明変数 = (N*N)*(7*4)のデータ\n",
    "        Y = [] # Y: 目的変数\n",
    "        point = [] # point: 緯度経度\n",
    "        X_28 = []\n",
    "        Y_28 = 0\n",
    "        point_28 = []\n",
    "        filenames = []\n",
    "        max_light = 0\n",
    "        print('inputdata_processing...')\n",
    "\n",
    "        labels = ['Water', 'Urban and built-up', 'Rice paddy',  'Crops', 'Grassland', 'DBF', 'DNF', 'EBF', 'ENF', 'Bare land' ]\n",
    "        for box in tqdm(range(trial)):\n",
    "            for imgfile in testfiles[box*28: (box+1)*28]:\n",
    "                # ZIPから画像読み込み\n",
    "                image = tifffile.imread(imgfile)\n",
    "        #         print(image.shape)\n",
    "                file = os.path.basename(imgfile)\n",
    "                file_split = [i for i in file.split('_')]\n",
    "                X_28.append(image)\n",
    "\n",
    "            Y_28 = int(file_split[4].split(\".\")[0]) - 1\n",
    "    #         print(file_split, Y_28)\n",
    "            point_28 = [float(file_split[0]), float(file_split[1])]\n",
    "            filenames.append(f\"test_{file_split[0]}_{file_split[1]}_{labels[Y_28]}\")\n",
    "            X.append(X_28[box*28: (box+1)*28])\n",
    "            Y.append(Y_28)\n",
    "            point.append(point_28)\n",
    "        del X_28, Y_28, point_28\n",
    "        X = np.asarray(X)\n",
    "        print(X.shape)\n",
    "        X = X.transpose(0,2,3,1)\n",
    "        print(X.shape)\n",
    "        Y = np.array(Y)\n",
    "        filenames = np.array(filenames)\n",
    "        point = np.array(point)\n",
    "        region = KMeans(n_clusters = outer_cvs, random_state=SEED).fit(point).labels_\n",
    "        df = [filenames, X, Y, point, region]\n",
    "        pkl_saver(df, os.path.join(data_path, f'df_{N}x{N}_testset.pkl'))\n",
    "        \n",
    "    return df\n",
    "def test_transform():\n",
    "    if os.path.exists(data_path + f'df_{N}x{N}_test_{standarization[standarization_num]}.pkl'):\n",
    "        df_test = pkl_loader(data_path + f'df_{N}x{N}_test_{standarization[standarization_num]}.pkl')\n",
    "        print(\"test_df をインポートしたよ！\")\n",
    "    else:\n",
    "        print(\"pklを新しく作成中ですが，標準化・正規化のコードに書き直しましたか？\")\n",
    "        X_test_zeros = np.zeros((X_test.shape[0], N*N*28))\n",
    "        for i in range(len(X_test)):\n",
    "            for k in range(N):\n",
    "                for l in range(N):\n",
    "                    for j in range(28):\n",
    "                        X_test_zeros[i][j+k+l] = X_test[i][k][l][j]\n",
    "        # X_test の名前が重複していたので違う名前に変えた. X_test_tmp\n",
    "        X_test_tmp = X_test_zeros\n",
    "        df_test = pd.concat([make_df(Y_test), make_df(X_test_tmp)], axis=1)\n",
    "        pkl_saver(df_test, os.path.join(data_path, f'df_{N}x{N}_test_{standarization[standarization_num]}.pkl'))\n",
    "        \n",
    "    return df_test.iloc[:, 1:], make_df(Y_test)\n",
    "def test_dem_import():\n",
    "    if os.path.exists(data_path + f'df_{N}x{N}_test_dem.pkl'):\n",
    "        df = pkl_loader(data_path + f'df_{N}x{N}_test_dem.pkl')\n",
    "    else:\n",
    "        trial = int(len(testfiles)/28)\n",
    "        X = [] # X: 説明変数 = (N*N)*(7*4)のデータ\n",
    "        Y = [] # Y: 目的変数\n",
    "        point = [] # point: 緯度経度\n",
    "        X_28 = []\n",
    "        Y_28 = 0\n",
    "        point_28 = []\n",
    "        filenames = []\n",
    "        max_light = 0\n",
    "        print('inputdata_processing...')\n",
    "\n",
    "        for box in tqdm(range(trial)):\n",
    "            for testfile in testfiles[box*28: (box+1)*28]:\n",
    "                # ZIPから画像読み込み\n",
    "                image = tifffile.imread(testfile)\n",
    "        #         print(image.shape)\n",
    "                file = os.path.basename(testfile)\n",
    "                file_split = [i for i in file.split('_')]\n",
    "                X_28.append(image[0][0])\n",
    "            dem_data = tifffile.imread(test_dem_files[box])[0][0]\n",
    "            X_28.append(dem_data)\n",
    "            Y_28 = file_split[4].split(\".\")[0]\n",
    "            point_28 = [float(file_split[0]), float(file_split[1])]\n",
    "            filenames.append(f\"{box}_{file_split[0]}_{file_split[1]}_{Y_28}\")\n",
    "            X.append(X_28[box*29: (box+1)*29])\n",
    "            Y.append(Y_28)\n",
    "            point.append(point_28)\n",
    "    #         if box==100:break\n",
    "        del X_28, Y_28, point_28\n",
    "        X = np.asarray(X)\n",
    "    #     X = X.transpose(0,2,3,1)\n",
    "        print(X.shape)\n",
    "        Y = np.array(Y)\n",
    "        filenames = np.array(filenames)\n",
    "        point = np.array(point)\n",
    "        region = KMeans(n_clusters = outer_cvs, random_state=SEED).fit(point).labels_\n",
    "        # label encorder===========================================\n",
    "        labels = ['Water', 'Urban and built-up', 'Rice paddy',  'Crops', 'Grassland', 'DBF', 'DNF', 'EBF', 'ENF', 'Bare land' ]\n",
    "        for i in range(len(labels)):\n",
    "            Y[Y==labels[i]] = int(i)\n",
    "        df = [filenames, X, Y, point, region]\n",
    "        pkl_saver(df, os.path.join(data_path, f'df_{N}x{N}_test_dem.pkl'))\n",
    "        \n",
    "    return df[0], df[1], df[2], df[3], df[4]\n",
    "\n",
    "def data_splitter_cv(filenames, X, Y, cv, region, point):\n",
    "    test_index = np.where(region==cv)\n",
    "    train_index = np.setdiff1d(np.arange(0, X.shape[0], 1), test_index)\n",
    "    train_files = filenames[train_index]\n",
    "    test_files = filenames[test_index]\n",
    "    X_test = X[test_index]\n",
    "    Y_test = Y[test_index]\n",
    "    X_train = X[train_index]\n",
    "    Y_train = Y[train_index]\n",
    "    train_region = region[train_index]\n",
    "    train_point = point[train_index]\n",
    "    return train_files, test_files, X_train, X_test, Y_train, Y_test, train_region, train_point\n",
    "\n",
    "# Loss Definition ----------------------------------\n",
    "def opt_cnn(trial):\n",
    "    # Opt params -----------------------\n",
    "    # Categorical parameter\n",
    "    num_layer = trial.suggest_int('num_layer', 1, 2)\n",
    "    dense_num = trial.suggest_int('dense_num', 3, 7)\n",
    "    num_filters = [int(trial.suggest_discrete_uniform(f'num_filter_{i}', 7, 10, 1)) for i in range(num_layer)]\n",
    "    size_filters = 3\n",
    "#     size_filters = [int(trial.suggest_discrete_uniform(f'size_filter_{i}', 3, 5, 2)) for i in range(num_layer)]\n",
    "    batch_size = trial.suggest_int('batch_size', 1, 5)\n",
    "    # Model Compiler -----------------------\n",
    "    lr = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "    decay = trial.suggest_loguniform('decay', 1e-6, 1e-3)\n",
    "    # Discrete-uniform parameter\n",
    "    dropout_rate_in = trial.suggest_discrete_uniform('dropout_rate_in', 0.0, 0.5, 0.1)\n",
    "    dropout_rate_out = trial.suggest_discrete_uniform('dropout_rate_out', 0.0, 0.5, 0.1)\n",
    "    momentum = trial.suggest_discrete_uniform('momentum', 0.0, 1.0, 0.1)\n",
    "    # categorical parameter\n",
    "#    optimizer = trial.suggest_categorical(\"optimizer\", [\"sgd\", \"momentum\", \"rmsprop\", \"adam\"])\n",
    "    padding = trial.suggest_categorical('padding', ['same'])\n",
    "    # compile model-------------------\n",
    "#     from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "    model = create_model(image_shape, num_layer, padding, dense_num, num_filters, size_filters, dropout_rate_in, dropout_rate_out)\n",
    "    sgd = optimizers.SGD(lr = lr, decay = decay, momentum = momentum, nesterov = True)\n",
    "#    sgd = optimizers.SGD(lr = lr, decay = decay, momentum = momentum, nesterov = True, clipvalue = 1.0)\n",
    "    # For CPU run ------------------\n",
    "    model.compile(optimizer = sgd, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    # Train Model ----------------------------------\n",
    "    es_cb = EarlyStopping(monitor = 'val_loss', patience = early_stopping, verbose = 0)\n",
    "    pr_cb = integration.TFKerasPruningCallback(trial, 'val_loss')\n",
    "    cbs = [es_cb, pr_cb]\n",
    "    loss_list, acc_list = [], []\n",
    "    for inner_cv in range(0, inner_cvs):\n",
    "        _, _, X_inner_train, X_inner_val, Y_inner_train, Y_inner_val, _, _ = data_splitter_cv(train_files, X_outer_train, Y_outer_train, inner_cv, val_train_region, val_train_point)\n",
    "        hist = model.fit(\n",
    "            train_datagen.flow(X_inner_train, Y_inner_train, batch_size = (2**batch_size) * gpus),\n",
    "            epochs = train_epochs,\n",
    "            validation_data = (X_inner_val, Y_inner_val),\n",
    "            callbacks = cbs,\n",
    "            shuffle = True,\n",
    "            verbose = 0,\n",
    "            use_multiprocessing = False)\n",
    "        loss_list += [model.evaluate(X_inner_val, Y_inner_val)[0]]\n",
    "        acc_list += [model.evaluate(X_inner_val, Y_inner_val)[1]]\n",
    "    del model\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    eval_loss = np.mean(loss_list)\n",
    "    eval_acc = np.mean(acc_list)\n",
    "    return eval_loss\n",
    "\n",
    "def create_model(image_shape, num_layer, padding, dense_num, num_filters, size_filters, dropout_rate_in, dropout_rate_out):\n",
    "    inputs = Input(image_shape)\n",
    "    for d in gpu_list:\n",
    "        with tf.device(d):\n",
    "            x = Dropout(dropout_rate_in)(inputs)\n",
    "            x = Convolution2D(filters = 2**num_filters[0], kernel_size = (size_filters[0],size_filters[0]), padding = 'same', activation = 'relu')(x)\n",
    "            for i in range(1, num_layer):\n",
    "                x = Convolution2D(filters = 2**num_filters[i],\n",
    "                                  kernel_size = (size_filters[i], size_filters[i]),\n",
    "                                  padding = padding,\n",
    "                                  activation = 'relu')(x)\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "            x = Dropout(dropout_rate_out)(x)\n",
    "            x = Dense(units = 2**dense_num, activation = 'relu')(x)\n",
    "            x = Dense(units = num_category, activation = 'softmax')(x)\n",
    "            model = Model(inputs = inputs, outputs = x)\n",
    "    return model\n",
    "\n",
    "def mean_params_calc(param_names):\n",
    "    dict = {}\n",
    "    categoricals = ['padding']\n",
    "    for param_name in param_names:\n",
    "        data_num = 0\n",
    "        if param_name not in categoricals:\n",
    "            for data in best_params:\n",
    "                try:\n",
    "                    try:\n",
    "                        dict[param_name] += data[param_name]\n",
    "                    except:\n",
    "                        dict[param_name] = data[param_name]\n",
    "                    data_num = data_num + 1\n",
    "                except:\n",
    "                    pass\n",
    "            dict[param_name] = dict[param_name]/data_num\n",
    "        else:\n",
    "            categorical_list = []\n",
    "            for data in best_params:\n",
    "                try:\n",
    "                    categorical_list = categorical_list + [data[param_name]]\n",
    "                except:\n",
    "                    pass\n",
    "            dict[param_name] = stats.mode(categorical_list)[0][0]\n",
    "    return dict\n",
    "\n",
    "def cv_result_imgs_generator(model, history):\n",
    "    # Visualize Loss Results ----------------------------\n",
    "    plt.figure(figsize=(18,6))\n",
    "    plt.plot(history.history[\"loss\"], label=\"loss\", marker=\"o\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"val_loss\", marker=\"o\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.title(\"\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(color='gray', alpha=0.2)\n",
    "    plt.savefig('./img_loss/' + str(outer_cv) + '_loss.jpg')\n",
    "    plt.close()\n",
    "\n",
    "def region_image_generator(point, region):\n",
    "    data_num = int(len(imgfiles)/28)\n",
    "    cmap = plt.get_cmap(\"tab10\")\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.scatter(point[:data_num][:,0],point[:data_num][:,1], marker='o', s=5, color=cmap(region))\n",
    "    ax.set_title(\"Region in Japan\")\n",
    "    ax.set_xlabel(\"longitude\")\n",
    "    ax.set_ylabel(\"latitude\")\n",
    "    fig.savefig('./region_separate.png')\n",
    "\n",
    "def make_dirs(model_name):\n",
    "    base_path = os.path.join(result_path , model_name)\n",
    "    # dir generation\n",
    "    dir_generator(base_path)\n",
    "    # Chenge current directry\n",
    "    os.mkdir(os.path.join(base_path, timename))\n",
    "    os.chdir(os.path.join(base_path, timename))\n",
    "    dir_generator(model_path)\n",
    "    dir_generator(\"./results/\")\n",
    "    dir_generator(\"./img_loss/\")\n",
    "    dir_generator(\"./model/\")\n",
    "    dir_generator(\"./weights/\")\n",
    "    dir_generator(\"./logs/\")\n",
    "    dir_generator(\"./outer_cv_times/\")\n",
    "\n",
    "def time_printer(start_time):\n",
    "    end_time = datetime.datetime.now()\n",
    "    spend_time = f\"Outer_cv time is {end_time - start_time} seconds.\"\n",
    "    \n",
    "# LightGBM ----------------------------------------------------\n",
    "# -------------------------------------------------------------\n",
    "def opt_lgb(trial):\n",
    "    if lgb_boosting_type == \"gbdt\":\n",
    "        param_grid_lgb = {\n",
    "    #         \"device\": \"gpu\",\n",
    "            'boosting_type': lgb_boosting_type,\n",
    "            'num_leaves': trial.suggest_int(\"num_leaves\", 15, 35),\n",
    "            'max_depth': trial.suggest_int(\"max_depth\", 5, 15),\n",
    "    #         'n_estimators': trial.suggest_int(\"n_estimators\", 70, 120),\n",
    "            'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 0.3),\n",
    "            \"random_state\": SEED\n",
    "        }\n",
    "    elif lgb_boosting_type ==\"rf\":\n",
    "        param_grid_lgb = {\n",
    "            'boosting_type': lgb_boosting_type,\n",
    "            'num_leaves': trial.suggest_int(\"num_leaves\", 15, 35),\n",
    "            'max_depth': trial.suggest_int(\"max_depth\", 5, 15),\n",
    "    #         'n_estimators': trial.suggest_int(\"n_estimators\", 70, 120),\n",
    "            'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 0.3),\n",
    "            \"random_state\": SEED\n",
    "        }\n",
    "    \n",
    "    scores = []\n",
    "    for inner_cv in range(inner_cvs):\n",
    "        _, _, X_inner_train, X_inner_val, Y_inner_train, Y_inner_val, _, _ = lgb_splitter_cv(train_files, X_outer_train, Y_outer_train, outer_cv, val_train_region, val_train_point)\n",
    "\n",
    "        model = LGBMClassifier(**param_grid_lgb)\n",
    "        model.fit(X_inner_train, Y_inner_train)\n",
    "        \n",
    "        scores.append(model.score(X_inner_val, Y_inner_val))\n",
    "    \n",
    "#     print('mean of inner_val_scores is ', np.mean(scores))\n",
    "    return np.mean(scores)\n",
    "\n",
    "def lgb_splitter_cv(filenames, X, Y, cv, region, point):\n",
    "#     from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "    test_index = np.where(region==cv)\n",
    "    train_index = np.setdiff1d(np.arange(0, X.shape[0], 1), test_index)\n",
    "    train_files = filenames[train_index]\n",
    "    test_files = filenames[test_index]\n",
    "    X_test = np.array(X)[test_index]\n",
    "    Y_test = np.array(Y)[test_index]\n",
    "    X_train = np.array(X)[train_index]\n",
    "    Y_train = np.array(Y)[train_index]\n",
    "    train_region = region[train_index]\n",
    "    train_point = point[train_index]\n",
    "    X_train, X_test, Y_train, Y_test = make_df(X_train), make_df(X_test), make_df(Y_train), make_df(Y_test)\n",
    "    return train_files, test_files, X_train, X_test, Y_train, Y_test, train_region, train_point\n",
    "\n",
    "def make_df(X):\n",
    "    return pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN (3x3 pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df をインポートしたよ！\n",
      "test_df をインポートしたよ！\n"
     ]
    }
   ],
   "source": [
    "# Data Loader ------------------------------------------------------------------------\n",
    "N=3\n",
    "standarization = [\"normalization\", \"Zscore\", \"normal\"] \n",
    "# pklを作るまではCodeの書き換えも必要だよ！\n",
    "standarization_num= 0\n",
    "lgb_boosting_type = 'CNN'\n",
    "\n",
    "\n",
    "##### Data Loader ------------------------------\n",
    "if under==20:\n",
    "    train_tif_name = f\"D:/LULC/features/01_landsat8/train_old/{N}x{N}\"\n",
    "elif under==90:\n",
    "    train_tif_name = f\"D:/LULC/features/01_landsat8/train_new/{N}x{N}\"\n",
    "\n",
    "testfiles = glob(f\"D:/LULC/features/01_landsat8/train_new/{N}x{N}_test\" + \"/*.tif\")\n",
    "testfiles.sort()\n",
    "root_path      = f\"C:/Users/GE/Dropbox/Kairo/under{under}_results/\"\n",
    "result_path    = f\"C:/Users/GE/Dropbox/Kairo/under{under}_results/{N}x{N}\"\n",
    "data_path      = f\"C:/Users/GE/Dropbox/Kairo/under{under}_results/data/\"\n",
    "model_path     = f\"C:/Users/GE/Dropbox/Kairo/under{under}_results/model/{N}x{N}/\"\n",
    "imgfiles = glob(train_tif_name + \"/*.tif\")\n",
    "imgfiles.sort()\n",
    "model_trained = False\n",
    "\n",
    "# data import ---------------------------------------------------------------------------\n",
    "timename       = '{0:%Y_%m%d_%H%M}'.format(datetime.datetime.now())\n",
    "time_path      =  os.path.join(result_path, lgb_boosting_type, timename, \"outer_cv_times\")\n",
    "# make_dirs(lgb_boosting_type)\n",
    "\n",
    "X_files, X_train, Y_train, train_point, region_train = train_import()\n",
    "X_train = X_train.astype(np.float64)\n",
    "image_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "num_category = len(np.unique(Y_train))\n",
    "\n",
    "Y_files, X_test, Y_test, test_point, region_test = test_import()\n",
    "X_test = X_test.astype(np.float64)\n",
    "\n",
    "X_train, Y_train = train_transform()\n",
    "X_test , Y_test  = test_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  <class 'pandas.core.frame.DataFrame'> (34088, 252)\n",
      "Y_train:  <class 'pandas.core.frame.DataFrame'> (34088, 1)\n",
      "X_test:  <class 'pandas.core.frame.DataFrame'> (3000, 252)\n",
      "Y_test:  <class 'pandas.core.frame.DataFrame'> (3000, 1)\n"
     ]
    }
   ],
   "source": [
    "# import data_shape check -------------------------------------------------------\n",
    "print(\"X_train: \", type(X_train), X_train.shape)\n",
    "print(\"Y_train: \", type(Y_train), Y_train.shape)\n",
    "print(\"X_test: \", type(X_test), X_test.shape)\n",
    "print(\"Y_test: \", type(Y_test), Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  <class 'numpy.ndarray'> (34088, 3, 3, 28)\n",
      "Y_train:  <class 'numpy.ndarray'> (34088, 1)\n",
      "X_test:  <class 'numpy.ndarray'> (3000, 3, 3, 28)\n",
      "Y_test:  <class 'numpy.ndarray'> (3000, 1)\n"
     ]
    }
   ],
   "source": [
    "# shape converter ------------------------------------\n",
    "X_train = X_train.values\n",
    "X_train = X_train.reshape(len(X_train), 3, 3, 28)\n",
    "X_test = X_test.values\n",
    "X_test = X_test.reshape(len(X_test), 3, 3, 28)\n",
    "Y_train = Y_train.values\n",
    "Y_test = Y_test.values\n",
    "\n",
    "print(\"X_train: \", type(X_train), X_train.shape)\n",
    "print(\"Y_train: \", type(Y_train), Y_train.shape)\n",
    "print(\"X_test: \", type(X_test), X_test.shape)\n",
    "print(\"Y_test: \", type(Y_test), Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer_cv_0_processing....\n",
      "15106/15106 [==============================] - 5s 333us/step\n",
      "15106/15106 [==============================] - 5s 330us/step\n",
      "1447/1447 [==============================] - 1s 363us/step\n",
      "1447/1447 [==============================] - 0s 328us/step\n",
      "1607/1607 [==============================] - 1s 338us/step\n",
      "1607/1607 [==============================] - 1s 332us/step\n",
      "2200/2200 [==============================] - 1s 334us/step\n",
      "2200/2200 [==============================] - 1s 331us/step\n",
      "815/815 [==============================] - 0s 398us/step\n",
      "815/815 [==============================] - 0s 336us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-01 13:36:39,102]\u001b[0m Finished trial#0 resulted in value: 2.183476812535688. Current best value is 2.183476812535688 with parameters: {'num_layer': 2, 'dense_num': 7, 'num_filter_0': 9.0, 'num_filter_1': 10.0, 'size_filter_0': 3.0, 'size_filter_1': 3.0, 'batch_size': 5, 'learning_rate': 0.003195367297244326, 'decay': 0.00022096978178245835, 'dropout_rate_in': 0.5, 'dropout_rate_out': 0.30000000000000004, 'momentum': 1.0, 'padding': 'same'}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15106/15106 [==============================] - 1s 61us/step\n",
      "15106/15106 [==============================] - 1s 63us/step\n",
      "1447/1447 [==============================] - 0s 74us/step\n",
      "1447/1447 [==============================] - 0s 63us/step\n",
      "1607/1607 [==============================] - 0s 63us/step\n",
      "1607/1607 [==============================] - 0s 64us/step\n",
      "2200/2200 [==============================] - 0s 64us/step\n",
      "2200/2200 [==============================] - 0s 63us/step\n",
      "815/815 [==============================] - 0s 82us/step\n",
      "815/815 [==============================] - 0s 73us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-01 13:46:42,927]\u001b[0m Finished trial#1 resulted in value: 1.902616871443079. Current best value is 1.902616871443079 with parameters: {'num_layer': 1, 'dense_num': 4, 'num_filter_0': 8.0, 'size_filter_0': 3.0, 'batch_size': 1, 'learning_rate': 0.0033537052350007144, 'decay': 3.846530002495511e-06, 'dropout_rate_in': 0.0, 'dropout_rate_out': 0.0, 'momentum': 0.8, 'padding': 'same'}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15106/15106 [==============================] - 1s 66us/step\n",
      "15106/15106 [==============================] - 1s 66us/step\n",
      "1447/1447 [==============================] - 0s 60us/step\n",
      "1447/1447 [==============================] - 0s 71us/step\n",
      "1607/1607 [==============================] - 0s 60us/step\n",
      "1607/1607 [==============================] - 0s 67us/step\n",
      "2200/2200 [==============================] - 0s 64us/step\n",
      "2200/2200 [==============================] - 0s 68us/step\n",
      "815/815 [==============================] - 0s 84us/step\n",
      "815/815 [==============================] - 0s 68us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-01 13:52:36,309]\u001b[0m Finished trial#2 resulted in value: 2.1870578621199988. Current best value is 1.902616871443079 with parameters: {'num_layer': 1, 'dense_num': 4, 'num_filter_0': 8.0, 'size_filter_0': 3.0, 'batch_size': 1, 'learning_rate': 0.0033537052350007144, 'decay': 3.846530002495511e-06, 'dropout_rate_in': 0.0, 'dropout_rate_out': 0.0, 'momentum': 0.8, 'padding': 'same'}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15106/15106 [==============================] - 2s 145us/step\n",
      "15106/15106 [==============================] - 2s 143us/step\n",
      "1447/1447 [==============================] - 0s 162us/step\n",
      "1447/1447 [==============================] - 0s 151us/step\n",
      "1607/1607 [==============================] - 0s 146us/step\n",
      "1607/1607 [==============================] - 0s 146us/step\n",
      "2200/2200 [==============================] - 0s 176us/step\n",
      "2200/2200 [==============================] - 0s 148us/step\n",
      "815/815 [==============================] - 0s 181us/step\n",
      "815/815 [==============================] - 0s 152us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-01 14:23:52,903]\u001b[0m Finished trial#3 resulted in value: 2.1138865077602995. Current best value is 1.902616871443079 with parameters: {'num_layer': 1, 'dense_num': 4, 'num_filter_0': 8.0, 'size_filter_0': 3.0, 'batch_size': 1, 'learning_rate': 0.0033537052350007144, 'decay': 3.846530002495511e-06, 'dropout_rate_in': 0.0, 'dropout_rate_out': 0.0, 'momentum': 0.8, 'padding': 'same'}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15106/15106 [==============================] - 2s 163us/step\n",
      "15106/15106 [==============================] - 2s 161us/step\n"
     ]
    }
   ],
   "source": [
    "# train start --------------------------------------\n",
    "train_start = datetime.datetime.now()\n",
    "# CV start ------------------------------------------------------------\n",
    "for outer_cv in range(outer_cvs):\n",
    "    outer_start = datetime.datetime.now()\n",
    "    print(f'outer_cv_{outer_cv}_processing....')\n",
    "    # Data Loader-------------------------------------\n",
    "    train_files, val_files, X_outer_train, X_outer_val, Y_outer_train, Y_outer_val, val_train_region, val_train_point = data_splitter_cv(X_files, X_train, Y_train, outer_cv, region_train, train_point)\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        horizontal_flip = True,\n",
    "        vertical_flip = True\n",
    "    )\n",
    "    val_train_region = KMeans(n_clusters = outer_cvs, random_state=SEED).fit(val_train_point).labels_\n",
    "    # Bayesian optimization -------------------------------------\n",
    "    study = optuna.create_study()\n",
    "    try:\n",
    "        study.optimize(opt_cnn, n_trials = n_trials)\n",
    "    except:\n",
    "        pass\n",
    "    # Best_model_training ---------------------------------------\n",
    "    num_filters = [int(study.best_params[f'num_filter_{i}']) for i in range(int(study.best_params['num_layer']))]\n",
    "    size_filters = [int(study.best_params[f'size_filter_{i}']) for i in range(int(study.best_params['num_layer']))]\n",
    "    model = create_model(image_shape, int(study.best_params['num_layer']), study.best_params['padding'], int(study.best_params['dense_num']), num_filters, size_filters, study.best_params['dropout_rate_in'], study.best_params['dropout_rate_out'])\n",
    "    sgd = optimizers.SGD(lr = study.best_params['learning_rate'], decay = study.best_params['decay'], momentum = study.best_params['momentum'], nesterov = True, clipvalue = 1.0)\n",
    "    model.compile(optimizer = sgd, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        train_datagen.flow(X_outer_train, Y_outer_train, batch_size = 2**int(study.best_params['batch_size']) * gpus),\n",
    "        epochs = train_epochs,\n",
    "        validation_data = (X_outer_val, Y_outer_val),\n",
    "        shuffle = True,\n",
    "        verbose = 0,\n",
    "        use_multiprocessing = False\n",
    "        )\n",
    "    try:         best_params.append(study.best_params)\n",
    "    except:      best_params = [study.best_params]\n",
    "    try:         val_pred_files = np.concatenate((val_pred_files, val_files), axis=0)\n",
    "    except:      val_pred_files = val_files\n",
    "    try:         Y_val_pred = np.concatenate((Y_val_pred, model.predict(X_outer_val).argmax(axis=1)), axis=0)\n",
    "    except:      Y_val_pred = np.array(model.predict(X_outer_val).argmax(axis=1))\n",
    "    try:         Y_val_obs = np.concatenate((Y_val_obs, Y_outer_val), axis=0)\n",
    "    except:      Y_val_obs = Y_outer_val\n",
    "    try:         Y_val_smx = np.concatenate((Y_val_smx, model.predict(X_outer_val)),axis=0)\n",
    "    except:      Y_val_smx = model.predict(X_outer_val)\n",
    "    \n",
    "    cv_result_imgs_generator(model, history)\n",
    "    print(\"accuracy is\", model.evaluate(X_outer_val, Y_outer_val)[1])\n",
    "    #compare_TV(history, outer_cv)\n",
    "    del model\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    outer_end = datetime.datetime.now()\n",
    "    spend_time = f\"Outer_cv time is {outer_end - outer_start} seconds.\"\n",
    "    pkl_saver(spend_time, os.path.join(time_path, f\"outer_cv_{outer_cv}_time.txt\"))\n",
    "\n",
    "train_end = datetime.datetime.now()\n",
    "spend_time = f\"Outer_cv time is {train_end - train_start} seconds.\"\n",
    "pkl_saver(spend_time, os.path.join(time_path, \"all_time.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save CV_Result -------------------------------------------------\n",
    "np.savetxt('Y_val_smx.txt', Y_val_smx)\n",
    "param_names = best_params[list(map(len, best_params)).index(max(list(map(len, best_params))))].keys()\n",
    "best_params_dict = mean_params_calc(param_names)\n",
    "pkl_saver(best_params, 'best_params_list.binaryfile')\n",
    "pkl_saver(best_params_dict, 'best_params.binaryfile')\n",
    "best_params_dict = pkl_loader('best_params.binaryfile')\n",
    "\n",
    "# Save CV_Result to csv -------------------------------------------------\n",
    "results = [val_pred_files, Y_val_obs, Y_val_pred, Y_val_smx]\n",
    "pkl_saver(results, './results/results.pkl')\n",
    "results_csv = np.concatenate([pd.DataFrame(val_pred_files),pd.DataFrame(Y_val_obs), pd.DataFrame(Y_val_pred), pd.DataFrame(Y_val_smx)], 1)\n",
    "results_csv = pd.DataFrame(results_csv)\n",
    "columns = [\"name\", \"obs\", \"pred\", 'Water', 'Urban and built-up', 'Rice paddy',  'Crops', 'Grassland', 'DBF', 'DNF', 'EBF', 'ENF', 'Bare land']\n",
    "results_csv.columns=columns\n",
    "results_csv.to_csv('./results/results_val.csv')\n",
    "labels = ['Water', 'Urban and built-up', 'Rice paddy',  'Crops', 'Grassland', 'DBF', 'DNF', 'EBF', 'ENF', 'Bare land']\n",
    "cf_metr = confusion_matrix(Y_val_obs.astype(int), Y_val_pred)\n",
    "cf_metr = pd.DataFrame(cf_metr)\n",
    "cf_metr.columns=labels\n",
    "cf_metr.index=labels\n",
    "cf_metr.to_csv(\"./results/confusion_matrix_val.csv\")\n",
    "\n",
    "res_smr = classification_report(list(results_csv['obs'].astype(int)), list(results_csv['pred']), target_names = labels, labels = np.array(range(len(labels))))\n",
    "with open('./results/result_summary_val.txt','w') as f:\n",
    "    f.write(res_smr)\n",
    "\n",
    "# Best Model Training -----------------------------------------------\n",
    "# Int parameter\n",
    "num_layer = int(best_params_dict['num_layer'])\n",
    "num_filters = [int(best_params_dict['num_filter_' + str(i)]) for i in range(num_layer)]\n",
    "size_filters = [int(best_params_dict['size_filter_' + str(i)]) for i in range(num_layer)]\n",
    "dense_num = int(best_params_dict['dense_num'])\n",
    "batch_size = int(best_params_dict['batch_size'])\n",
    "# Uniform parameter\n",
    "# Loguniform parameter\n",
    "lr = best_params_dict['learning_rate']\n",
    "decay = best_params_dict['decay']\n",
    "# Discrete-uniform parameter\n",
    "dropout_rate_in = best_params_dict['dropout_rate_in']\n",
    "dropout_rate_out = best_params_dict['dropout_rate_out']\n",
    "momentum = best_params_dict['momentum']\n",
    "# Categorical parameter\n",
    "padding = best_params_dict['padding']\n",
    "\n",
    "\n",
    "# Model Checkpoint ------------------\n",
    "cp_cb = ModelCheckpoint(\n",
    "    './weights/best_weights.hdf5',\n",
    "    monitor = 'val_loss',\n",
    "    verbose = 1,\n",
    "    save_best_only = True,\n",
    "    save_weights_only = True,\n",
    "    mode = 'auto')\n",
    "# Logging ----------------------------------------\n",
    "log_dir = os.path.join('./logs/')\n",
    "tb_cb = TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True)\n",
    "es_cb = EarlyStopping(monitor = 'val_loss', patience = int(best_epochs/10), verbose = 1)\n",
    "\n",
    "cbs = [cp_cb, tb_cb, es_cb]\n",
    "# Train Best_Model ----------------------------------\n",
    "# For CPU run ------------------\n",
    "best_model = create_model(image_shape, num_layer, padding, dense_num, num_filters, size_filters, dropout_rate_in, dropout_rate_out)\n",
    "sgd = optimizers.SGD(lr = lr, decay = decay, momentum = momentum, nesterov = True, clipvalue = 1.0)\n",
    "\n",
    "best_model.compile(optimizer = sgd, loss = 'sparse_categorical_crossentropy')\n",
    "hist = best_model.fit(\n",
    "    train_datagen.flow(X_train, Y_train, batch_size = (2**batch_size) * gpus),\n",
    "    epochs = best_epochs,\n",
    "    callbacks = cbs,\n",
    "    shuffle = True,\n",
    "    verbose = 1,\n",
    "    initial_epoch = 0,\n",
    "    use_multiprocessing = False)\n",
    "\n",
    "# Save Model -----------------------------------\n",
    "best_model.save('./model/best_model.hdf5')\n",
    "model_trained = True\n",
    "\n",
    "# Save Code\n",
    "import shutil\n",
    "os.mkdir(\"./code\")\n",
    "shutil.copy(ipynb_path.get(), f\"./code/{ipynb_path.get().split(\"/\")[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# モデルのインポート: ここだけは手動で指定する or モデル学習後なら触らない\n",
    "if model_trained == False:\n",
    "    print(\"timename を手動で設定しましたか？\")\n",
    "    timename = \"2020_1109_1712\"\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ロードだけでも動くように変数の再定義=============================================\n",
    "# ==============================================================================\n",
    "# ==============================================================================\n",
    "# ==============================================================================\n",
    "# ==============================================================================\n",
    "os.chdir(os.path.join(result_path, timename))\n",
    "# Data Loader ------------------------------\n",
    "best_model = load_model(\"./model/best_model.hdf5\")\n",
    "df = pkl_loader(os.path.join(data_path, f'df_{N}x{N}.pkl'))\n",
    "# Data converter ----------------------------------------------\n",
    "filenames, X, Y, point, region = df[0], df[1], df[2], df[3], df[4]\n",
    "image_shape = (X.shape[1], X.shape[2], X.shape[3])\n",
    "num_category = len(np.unique(Y))\n",
    "# Data splitting ----------------------------------------------\n",
    "X_train_mean_lis = []\n",
    "X_train_std_lis = []\n",
    "X_files, Y_files, X_train, X_test, Y_train, Y_test, region_train, _, train_point, _ = train_test_split(filenames, X, Y, region, point, test_size=0.2, random_state=SEED)\n",
    "\n",
    "for i in range(X_train.shape[3]):\n",
    "    X_train_mean_lis.append(X_train[:,:,:,i].mean())\n",
    "    X_train_std_lis.append(X_train[:,:,:,i].std())\n",
    "    X_train[:,:,:,i] = (X_train[:,:,:,i] - X_train_mean_lis[i])/X_train_std_lis[i]\n",
    "    X_test[:,:,:,i] = (X_test[:,:,:,i] - X_train_mean_lis[i])/X_train_std_lis[i]\n",
    "# ==============================================================================\n",
    "# ==============================================================================\n",
    "# ==============================================================================\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "Y_test_pred = [ np.array(best_model.predict(X_test).argmax(axis=1))]\n",
    "np.savetxt('y_test_pred.txt', Y_test_pred)\n",
    "with open(\"best_model_summary.txt\", \"w\") as fp:\n",
    "    best_model.summary(print_fn=lambda x: fp.write(x + \"\\r\\n\"))\n",
    "\n",
    "    \n",
    "results = [Y_files, Y_test, Y_test_pred]\n",
    "pkl_saver(results, './results/results.pkl')\n",
    "results_csv = np.concatenate([pd.DataFrame(Y_files),pd.DataFrame(Y_test), pd.DataFrame(Y_test_pred[0])], 1)\n",
    "results_csv = pd.DataFrame(results_csv)\n",
    "columns = [\"name\", \"obs\", \"pred\"]\n",
    "results_csv.columns=columns\n",
    "results_csv.to_csv('./results/results_test.csv')\n",
    "labels = ['Water', 'Urban and built-up', 'Rice paddy',  'Crops', 'Grassland', 'DBF', 'DNF', 'EBF', 'ENF', 'Bare land']\n",
    "cf_metr = confusion_matrix(Y_test.astype(int), Y_test_pred[0])\n",
    "cf_metr = pd.DataFrame(cf_metr)\n",
    "cf_metr.columns=labels\n",
    "cf_metr.index=labels\n",
    "cf_metr.to_csv(\"./results/confusion_matrix_test.csv\")\n",
    "test_smr = classification_report(list(np.array(Y_test).astype(int)), list(Y_test_pred[0].astype(int)), target_names = labels, labels = np.array(range(len(labels))))\n",
    "with open('./results/result_summary_test.txt','w') as f:\n",
    "    f.write(test_smr)\n",
    "    \n",
    "print('finished...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Show Accuracy --------------------------------------------------------------------------\n",
    "acc = round((np.array(Y_test_pred).astype(int) == Y_test.astype(int)).sum() / len(Y_test), 3)*100\n",
    "print(acc)\n",
    "pkl_saver(acc, f'acc_{acc}.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM (1x1 pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df をインポートしたよ！\n",
      "test_df をインポートしたよ！\n"
     ]
    }
   ],
   "source": [
    "# Data Loader ------------------------------------------------------------------------\n",
    "standarization = [\"normalization\", \"Zscore\", \"normal\", \"dem\"] # pklを作るまではCodeの書き換えも必要だよ！\n",
    "standarization_num= 2\n",
    "N=1\n",
    "\n",
    "##### Data Loader ------------------------------\n",
    "if under==20:\n",
    "    train_tif_name = f\"D:/LULC/features/01_landsat8/train_old/{N}x{N}\"\n",
    "elif under==90:\n",
    "    train_tif_name = f\"D:/LULC/features/01_landsat8/train_new/{N}x{N}\"\n",
    "\n",
    "testfiles = glob(f\"D:/LULC/features/01_landsat8/train_new/{N}x{N}_test\" + \"/*.tif\")\n",
    "testfiles.sort()\n",
    "\n",
    "root_path      = f\"C:/Users/GE/Dropbox/Kairo/under{under}_results/\"\n",
    "result_path    = f\"C:/Users/GE/Dropbox/Kairo/under{under}_results/{N}x{N}\"\n",
    "data_path      = f\"C:/Users/GE/Dropbox/Kairo/under{under}_results/data/\"\n",
    "model_path     = f\"C:/Users/GE/Dropbox/Kairo/under{under}_results/model/{N}x{N}/\"\n",
    "imgfiles = glob(train_tif_name + \"/*.tif\")\n",
    "imgfiles.sort()\n",
    "model_trained = False\n",
    "\n",
    "# data import ---------------------------------------------------------------------------\n",
    "timename       = '{0:%Y_%m%d_%H%M}'.format(datetime.datetime.now())\n",
    "time_path      =  os.path.join(result_path, lgb_boosting_type, timename, \"outer_cv_times\")\n",
    "make_dirs(lgb_boosting_type)\n",
    "# ------------train import----------------------\n",
    "X_files, X_train, Y_train, train_point, region_train = train_import()\n",
    "image_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "num_category = len(np.unique(Y_train))\n",
    "X_train = X_train.astype(np.float64)\n",
    "Y_train = Y_train.astype(np.float64)\n",
    "# ------------test import----------------------\n",
    "Y_files, X_test, Y_test, test_point, region_test = test_import()\n",
    "X_test = X_test.astype(np.float64)\n",
    "\n",
    "\n",
    "# Data converter ----------------------------------------------\n",
    "X_train, Y_train = train_transform()\n",
    "X_test, Y_test = test_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  <class 'pandas.core.frame.DataFrame'> (34088, 28)\n",
      "Y_train:  <class 'pandas.core.frame.DataFrame'> (34088, 1)\n",
      "X_test:  <class 'pandas.core.frame.DataFrame'> (3000, 28)\n",
      "Y_test:  <class 'pandas.core.frame.DataFrame'> (3000, 1)\n"
     ]
    }
   ],
   "source": [
    "# import data_shape check -------------------------------------------------------------\n",
    "print(\"X_train: \", type(X_train), X_train.shape)\n",
    "print(\"Y_train: \", type(Y_train), Y_train.shape)\n",
    "print(\"X_test: \", type(X_test), X_test.shape)\n",
    "print(\"Y_test: \", type(Y_test), Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# del Y_val_files, lgb_scores, lgb_best_params,  Y_val_smx, Y_val_pred, Y_val_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer_cv_0_processing....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-01 09:42:21,479]\u001b[0m Finished trial#0 resulted in value: 0.26539123527075337. Current best value is 0.26539123527075337 with parameters: {'num_leaves': 24, 'max_depth': 12, 'learning_rate': 0.0002658722139302497}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:42:30,930]\u001b[0m Finished trial#1 resulted in value: 0.26539123527075337. Current best value is 0.26539123527075337 with parameters: {'num_leaves': 24, 'max_depth': 12, 'learning_rate': 0.0002658722139302497}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:42:40,576]\u001b[0m Finished trial#2 resulted in value: 0.43578710446180324. Current best value is 0.43578710446180324 with parameters: {'num_leaves': 31, 'max_depth': 5, 'learning_rate': 0.00542693739019227}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:42:51,047]\u001b[0m Finished trial#3 resulted in value: 0.26539123527075337. Current best value is 0.43578710446180324 with parameters: {'num_leaves': 31, 'max_depth': 5, 'learning_rate': 0.00542693739019227}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:43:01,104]\u001b[0m Finished trial#4 resulted in value: 0.26539123527075337. Current best value is 0.43578710446180324 with parameters: {'num_leaves': 31, 'max_depth': 5, 'learning_rate': 0.00542693739019227}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:43:13,529]\u001b[0m Finished trial#5 resulted in value: 0.26539123527075337. Current best value is 0.43578710446180324 with parameters: {'num_leaves': 31, 'max_depth': 5, 'learning_rate': 0.00542693739019227}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:43:22,923]\u001b[0m Finished trial#6 resulted in value: 0.26539123527075337. Current best value is 0.43578710446180324 with parameters: {'num_leaves': 31, 'max_depth': 5, 'learning_rate': 0.00542693739019227}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:43:33,424]\u001b[0m Finished trial#7 resulted in value: 0.26539123527075337. Current best value is 0.43578710446180324 with parameters: {'num_leaves': 31, 'max_depth': 5, 'learning_rate': 0.00542693739019227}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:43:44,413]\u001b[0m Finished trial#8 resulted in value: 0.5237653912352708. Current best value is 0.5237653912352708 with parameters: {'num_leaves': 25, 'max_depth': 11, 'learning_rate': 0.012400515059761323}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:43:52,538]\u001b[0m Finished trial#9 resulted in value: 0.26539123527075337. Current best value is 0.5237653912352708 with parameters: {'num_leaves': 25, 'max_depth': 11, 'learning_rate': 0.012400515059761323}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:44:01,869]\u001b[0m Finished trial#10 resulted in value: 0.5571958162319608. Current best value is 0.5571958162319608 with parameters: {'num_leaves': 20, 'max_depth': 9, 'learning_rate': 0.1640808447423859}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:44:10,604]\u001b[0m Finished trial#11 resulted in value: 0.5606381570236992. Current best value is 0.5606381570236992 with parameters: {'num_leaves': 19, 'max_depth': 9, 'learning_rate': 0.28488525830476347}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:44:18,994]\u001b[0m Finished trial#12 resulted in value: 0.5536210777174633. Current best value is 0.5606381570236992 with parameters: {'num_leaves': 19, 'max_depth': 9, 'learning_rate': 0.28488525830476347}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:44:28,170]\u001b[0m Finished trial#13 resulted in value: 0.5540844697471203. Current best value is 0.5606381570236992 with parameters: {'num_leaves': 19, 'max_depth': 9, 'learning_rate': 0.28488525830476347}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:44:35,985]\u001b[0m Finished trial#14 resulted in value: 0.5575268105388588. Current best value is 0.5606381570236992 with parameters: {'num_leaves': 19, 'max_depth': 9, 'learning_rate': 0.28488525830476347}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:44:44,362]\u001b[0m Finished trial#15 resulted in value: 0.513703164305574. Current best value is 0.5606381570236992 with parameters: {'num_leaves': 19, 'max_depth': 9, 'learning_rate': 0.28488525830476347}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:44:51,739]\u001b[0m Finished trial#16 resulted in value: 0.55256189593539. Current best value is 0.5606381570236992 with parameters: {'num_leaves': 19, 'max_depth': 9, 'learning_rate': 0.28488525830476347}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:45:01,213]\u001b[0m Finished trial#17 resulted in value: 0.5391897259367139. Current best value is 0.5606381570236992 with parameters: {'num_leaves': 19, 'max_depth': 9, 'learning_rate': 0.28488525830476347}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:45:08,416]\u001b[0m Finished trial#18 resulted in value: 0.26539123527075337. Current best value is 0.5606381570236992 with parameters: {'num_leaves': 19, 'max_depth': 9, 'learning_rate': 0.28488525830476347}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:45:16,872]\u001b[0m Finished trial#19 resulted in value: 0.29398914338673376. Current best value is 0.5606381570236992 with parameters: {'num_leaves': 19, 'max_depth': 9, 'learning_rate': 0.28488525830476347}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:45:27,420]\u001b[0m Finished trial#20 resulted in value: 0.5505097312326228. Current best value is 0.5606381570236992 with parameters: {'num_leaves': 19, 'max_depth': 9, 'learning_rate': 0.28488525830476347}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:45:36,534]\u001b[0m Finished trial#21 resulted in value: 0.5559380378657487. Current best value is 0.5606381570236992 with parameters: {'num_leaves': 19, 'max_depth': 9, 'learning_rate': 0.28488525830476347}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:45:46,675]\u001b[0m Finished trial#22 resulted in value: 0.5550774526678142. Current best value is 0.5606381570236992 with parameters: {'num_leaves': 19, 'max_depth': 9, 'learning_rate': 0.28488525830476347}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:45:55,597]\u001b[0m Finished trial#23 resulted in value: 0.5536210777174633. Current best value is 0.5606381570236992 with parameters: {'num_leaves': 19, 'max_depth': 9, 'learning_rate': 0.28488525830476347}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:46:03,902]\u001b[0m Finished trial#24 resulted in value: 0.5419700781146565. Current best value is 0.5606381570236992 with parameters: {'num_leaves': 19, 'max_depth': 9, 'learning_rate': 0.28488525830476347}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:46:12,385]\u001b[0m Finished trial#25 resulted in value: 0.35197934595524955. Current best value is 0.5606381570236992 with parameters: {'num_leaves': 19, 'max_depth': 9, 'learning_rate': 0.28488525830476347}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:46:23,042]\u001b[0m Finished trial#26 resulted in value: 0.5439560439560439. Current best value is 0.5606381570236992 with parameters: {'num_leaves': 19, 'max_depth': 9, 'learning_rate': 0.28488525830476347}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:46:31,934]\u001b[0m Finished trial#27 resulted in value: 0.5530914868264266. Current best value is 0.5606381570236992 with parameters: {'num_leaves': 19, 'max_depth': 9, 'learning_rate': 0.28488525830476347}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:46:39,978]\u001b[0m Finished trial#28 resulted in value: 0.26539123527075337. Current best value is 0.5606381570236992 with parameters: {'num_leaves': 19, 'max_depth': 9, 'learning_rate': 0.28488525830476347}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:46:49,058]\u001b[0m Finished trial#29 resulted in value: 0.26539123527075337. Current best value is 0.5606381570236992 with parameters: {'num_leaves': 19, 'max_depth': 9, 'learning_rate': 0.28488525830476347}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:46:58,234]\u001b[0m Finished trial#30 resulted in value: 0.26539123527075337. Current best value is 0.5606381570236992 with parameters: {'num_leaves': 19, 'max_depth': 9, 'learning_rate': 0.28488525830476347}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:47:07,955]\u001b[0m Finished trial#31 resulted in value: 0.5513041175691779. Current best value is 0.5606381570236992 with parameters: {'num_leaves': 19, 'max_depth': 9, 'learning_rate': 0.28488525830476347}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of outer_val_scores is  0.5567528735632183\n",
      "mean of test_scores is  0.6426666666666667\n",
      "outer_cv_1_processing....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-01 09:47:24,966]\u001b[0m Finished trial#0 resulted in value: 0.3161764705882353. Current best value is 0.3161764705882353 with parameters: {'num_leaves': 33, 'max_depth': 9, 'learning_rate': 2.2745929098592027e-05}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:47:34,032]\u001b[0m Finished trial#1 resulted in value: 0.3161764705882353. Current best value is 0.3161764705882353 with parameters: {'num_leaves': 33, 'max_depth': 9, 'learning_rate': 2.2745929098592027e-05}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:47:47,535]\u001b[0m Finished trial#2 resulted in value: 0.3161764705882353. Current best value is 0.3161764705882353 with parameters: {'num_leaves': 33, 'max_depth': 9, 'learning_rate': 2.2745929098592027e-05}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:48:01,136]\u001b[0m Finished trial#3 resulted in value: 0.6197478991596639. Current best value is 0.6197478991596639 with parameters: {'num_leaves': 27, 'max_depth': 8, 'learning_rate': 0.006355745755743054}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:48:16,700]\u001b[0m Finished trial#4 resulted in value: 0.648109243697479. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:48:29,814]\u001b[0m Finished trial#5 resulted in value: 0.3161764705882353. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:48:42,066]\u001b[0m Finished trial#6 resulted in value: 0.6397058823529411. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:48:53,961]\u001b[0m Finished trial#7 resulted in value: 0.3161764705882353. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:49:03,619]\u001b[0m Finished trial#8 resulted in value: 0.3161764705882353. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:49:16,056]\u001b[0m Finished trial#9 resulted in value: 0.3161764705882353. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:49:31,453]\u001b[0m Finished trial#10 resulted in value: 0.5462184873949579. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:49:40,801]\u001b[0m Finished trial#11 resulted in value: 0.6365546218487395. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:49:53,924]\u001b[0m Finished trial#12 resulted in value: 0.6407563025210085. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:50:08,262]\u001b[0m Finished trial#13 resulted in value: 0.32037815126050423. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:50:22,419]\u001b[0m Finished trial#14 resulted in value: 0.6313025210084033. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:50:36,525]\u001b[0m Finished trial#15 resulted in value: 0.3161764705882353. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:50:50,746]\u001b[0m Finished trial#16 resulted in value: 0.6418067226890757. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:51:05,498]\u001b[0m Finished trial#17 resulted in value: 0.6376050420168067. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:51:20,641]\u001b[0m Finished trial#18 resulted in value: 0.3161764705882353. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:51:35,441]\u001b[0m Finished trial#19 resulted in value: 0.6418067226890757. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:51:49,755]\u001b[0m Finished trial#20 resulted in value: 0.6397058823529411. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:52:04,229]\u001b[0m Finished trial#21 resulted in value: 0.6449579831932774. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:52:20,308]\u001b[0m Finished trial#22 resulted in value: 0.6397058823529411. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:52:35,645]\u001b[0m Finished trial#23 resulted in value: 0.6418067226890757. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:52:50,743]\u001b[0m Finished trial#24 resulted in value: 0.3161764705882353. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:53:06,011]\u001b[0m Finished trial#25 resulted in value: 0.6365546218487395. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:53:20,948]\u001b[0m Finished trial#26 resulted in value: 0.6407563025210085. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:53:33,374]\u001b[0m Finished trial#27 resulted in value: 0.3161764705882353. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:53:47,065]\u001b[0m Finished trial#28 resulted in value: 0.6460084033613446. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:54:01,105]\u001b[0m Finished trial#29 resulted in value: 0.3224789915966387. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:54:14,138]\u001b[0m Finished trial#30 resulted in value: 0.3161764705882353. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:54:28,801]\u001b[0m Finished trial#31 resulted in value: 0.6271008403361344. Current best value is 0.648109243697479 with parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.026865460582462593}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of outer_val_scores is  0.6744615384615384\n",
      "mean of test_scores is  0.59\n",
      "outer_cv_2_processing....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-01 09:54:43,590]\u001b[0m Finished trial#0 resulted in value: 0.2457852706299911. Current best value is 0.2457852706299911 with parameters: {'num_leaves': 20, 'max_depth': 9, 'learning_rate': 0.000594843553674416}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:54:54,607]\u001b[0m Finished trial#1 resulted in value: 0.2457852706299911. Current best value is 0.2457852706299911 with parameters: {'num_leaves': 20, 'max_depth': 9, 'learning_rate': 0.000594843553674416}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:55:07,673]\u001b[0m Finished trial#2 resulted in value: 0.2457852706299911. Current best value is 0.2457852706299911 with parameters: {'num_leaves': 20, 'max_depth': 9, 'learning_rate': 0.000594843553674416}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:55:21,423]\u001b[0m Finished trial#3 resulted in value: 0.2457852706299911. Current best value is 0.2457852706299911 with parameters: {'num_leaves': 20, 'max_depth': 9, 'learning_rate': 0.000594843553674416}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:55:34,520]\u001b[0m Finished trial#4 resulted in value: 0.2457852706299911. Current best value is 0.2457852706299911 with parameters: {'num_leaves': 20, 'max_depth': 9, 'learning_rate': 0.000594843553674416}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:55:45,709]\u001b[0m Finished trial#5 resulted in value: 0.2457852706299911. Current best value is 0.2457852706299911 with parameters: {'num_leaves': 20, 'max_depth': 9, 'learning_rate': 0.000594843553674416}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:55:55,822]\u001b[0m Finished trial#6 resulted in value: 0.2457852706299911. Current best value is 0.2457852706299911 with parameters: {'num_leaves': 20, 'max_depth': 9, 'learning_rate': 0.000594843553674416}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:56:08,574]\u001b[0m Finished trial#7 resulted in value: 0.5563442768411713. Current best value is 0.5563442768411713 with parameters: {'num_leaves': 23, 'max_depth': 14, 'learning_rate': 0.009335445082482546}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:56:17,700]\u001b[0m Finished trial#8 resulted in value: 0.2457852706299911. Current best value is 0.5563442768411713 with parameters: {'num_leaves': 23, 'max_depth': 14, 'learning_rate': 0.009335445082482546}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:56:32,734]\u001b[0m Finished trial#9 resulted in value: 0.5705412599822538. Current best value is 0.5705412599822538 with parameters: {'num_leaves': 30, 'max_depth': 10, 'learning_rate': 0.018436266407196512}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:56:46,809]\u001b[0m Finished trial#10 resulted in value: 0.6264418811002662. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:57:00,735]\u001b[0m Finished trial#11 resulted in value: 0.6246672582076309. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:57:14,191]\u001b[0m Finished trial#12 resulted in value: 0.6184560780834073. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:57:28,084]\u001b[0m Finished trial#13 resulted in value: 0.614019520851819. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:57:43,227]\u001b[0m Finished trial#14 resulted in value: 0.5616681455190772. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:57:53,729]\u001b[0m Finished trial#15 resulted in value: 0.6149068322981367. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:58:07,560]\u001b[0m Finished trial#16 resulted in value: 0.3105590062111801. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:58:23,077]\u001b[0m Finished trial#17 resulted in value: 0.6069210292812778. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:58:35,784]\u001b[0m Finished trial#18 resulted in value: 0.2457852706299911. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:58:50,254]\u001b[0m Finished trial#19 resulted in value: 0.6246672582076309. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:59:02,949]\u001b[0m Finished trial#20 resulted in value: 0.24223602484472054. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:59:16,949]\u001b[0m Finished trial#21 resulted in value: 0.616681455190772. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:59:32,892]\u001b[0m Finished trial#22 resulted in value: 0.5918367346938775. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 09:59:45,284]\u001b[0m Finished trial#23 resulted in value: 0.6228926353149956. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:00:01,122]\u001b[0m Finished trial#24 resulted in value: 0.6060337178349601. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:00:15,858]\u001b[0m Finished trial#25 resulted in value: 0.5004436557231589. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:00:26,355]\u001b[0m Finished trial#26 resulted in value: 0.6193433895297249. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:00:41,549]\u001b[0m Finished trial#27 resulted in value: 0.6228926353149956. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:00:53,833]\u001b[0m Finished trial#28 resulted in value: 0.2457852706299911. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:01:07,824]\u001b[0m Finished trial#29 resulted in value: 0.2457852706299911. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:01:21,434]\u001b[0m Finished trial#30 resulted in value: 0.5643300798580302. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:01:36,687]\u001b[0m Finished trial#31 resulted in value: 0.6193433895297249. Current best value is 0.6264418811002662 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.16708751383000212}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of outer_val_scores is  0.6439075630252101\n",
      "mean of test_scores is  0.6663333333333333\n",
      "outer_cv_3_processing....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-01 10:01:54,046]\u001b[0m Finished trial#0 resulted in value: 0.31724754244861486. Current best value is 0.31724754244861486 with parameters: {'num_leaves': 32, 'max_depth': 11, 'learning_rate': 1.270052391591873e-08}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:02:04,687]\u001b[0m Finished trial#1 resulted in value: 0.31724754244861486. Current best value is 0.31724754244861486 with parameters: {'num_leaves': 32, 'max_depth': 11, 'learning_rate': 1.270052391591873e-08}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:02:19,004]\u001b[0m Finished trial#2 resulted in value: 0.31724754244861486. Current best value is 0.31724754244861486 with parameters: {'num_leaves': 32, 'max_depth': 11, 'learning_rate': 1.270052391591873e-08}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:02:28,038]\u001b[0m Finished trial#3 resulted in value: 0.31724754244861486. Current best value is 0.31724754244861486 with parameters: {'num_leaves': 32, 'max_depth': 11, 'learning_rate': 1.270052391591873e-08}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:02:41,494]\u001b[0m Finished trial#4 resulted in value: 0.31724754244861486. Current best value is 0.31724754244861486 with parameters: {'num_leaves': 32, 'max_depth': 11, 'learning_rate': 1.270052391591873e-08}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:02:53,747]\u001b[0m Finished trial#5 resulted in value: 0.31724754244861486. Current best value is 0.31724754244861486 with parameters: {'num_leaves': 32, 'max_depth': 11, 'learning_rate': 1.270052391591873e-08}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:03:02,280]\u001b[0m Finished trial#6 resulted in value: 0.31814119749776587. Current best value is 0.31814119749776587 with parameters: {'num_leaves': 15, 'max_depth': 5, 'learning_rate': 0.0012781233011794361}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:03:14,921]\u001b[0m Finished trial#7 resulted in value: 0.31724754244861486. Current best value is 0.31814119749776587 with parameters: {'num_leaves': 15, 'max_depth': 5, 'learning_rate': 0.0012781233011794361}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:03:24,626]\u001b[0m Finished trial#8 resulted in value: 0.31724754244861486. Current best value is 0.31814119749776587 with parameters: {'num_leaves': 15, 'max_depth': 5, 'learning_rate': 0.0012781233011794361}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:03:36,958]\u001b[0m Finished trial#9 resulted in value: 0.31724754244861486. Current best value is 0.31814119749776587 with parameters: {'num_leaves': 15, 'max_depth': 5, 'learning_rate': 0.0012781233011794361}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:03:46,726]\u001b[0m Finished trial#10 resulted in value: 0.6434316353887399. Current best value is 0.6434316353887399 with parameters: {'num_leaves': 21, 'max_depth': 5, 'learning_rate': 0.0864468369290268}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:03:55,978]\u001b[0m Finished trial#11 resulted in value: 0.6501340482573726. Current best value is 0.6501340482573726 with parameters: {'num_leaves': 21, 'max_depth': 5, 'learning_rate': 0.1922743374144869}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:04:05,278]\u001b[0m Finished trial#12 resulted in value: 0.6470062555853441. Current best value is 0.6501340482573726 with parameters: {'num_leaves': 21, 'max_depth': 5, 'learning_rate': 0.1922743374144869}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:04:14,811]\u001b[0m Finished trial#13 resulted in value: 0.6537086684539768. Current best value is 0.6537086684539768 with parameters: {'num_leaves': 22, 'max_depth': 5, 'learning_rate': 0.16415368471126188}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:04:27,344]\u001b[0m Finished trial#14 resulted in value: 0.6322609472743521. Current best value is 0.6537086684539768 with parameters: {'num_leaves': 22, 'max_depth': 5, 'learning_rate': 0.16415368471126188}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:04:39,768]\u001b[0m Finished trial#15 resulted in value: 0.6161751563896336. Current best value is 0.6537086684539768 with parameters: {'num_leaves': 22, 'max_depth': 5, 'learning_rate': 0.16415368471126188}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:04:49,747]\u001b[0m Finished trial#16 resulted in value: 0.5996425379803396. Current best value is 0.6537086684539768 with parameters: {'num_leaves': 22, 'max_depth': 5, 'learning_rate': 0.16415368471126188}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:05:01,013]\u001b[0m Finished trial#17 resulted in value: 0.6514745308310992. Current best value is 0.6537086684539768 with parameters: {'num_leaves': 22, 'max_depth': 5, 'learning_rate': 0.16415368471126188}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:05:12,694]\u001b[0m Finished trial#18 resulted in value: 0.31724754244861486. Current best value is 0.6537086684539768 with parameters: {'num_leaves': 22, 'max_depth': 5, 'learning_rate': 0.16415368471126188}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:05:26,463]\u001b[0m Finished trial#19 resulted in value: 0.5705987488829312. Current best value is 0.6537086684539768 with parameters: {'num_leaves': 22, 'max_depth': 5, 'learning_rate': 0.16415368471126188}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:05:37,825]\u001b[0m Finished trial#20 resulted in value: 0.6613047363717605. Current best value is 0.6613047363717605 with parameters: {'num_leaves': 23, 'max_depth': 12, 'learning_rate': 0.27688583700227487}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:05:49,296]\u001b[0m Finished trial#21 resulted in value: 0.6505808757819481. Current best value is 0.6613047363717605 with parameters: {'num_leaves': 23, 'max_depth': 12, 'learning_rate': 0.27688583700227487}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:06:00,252]\u001b[0m Finished trial#22 resulted in value: 0.6358355674709563. Current best value is 0.6613047363717605 with parameters: {'num_leaves': 23, 'max_depth': 12, 'learning_rate': 0.27688583700227487}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:06:11,998]\u001b[0m Finished trial#23 resulted in value: 0.6523681858802503. Current best value is 0.6613047363717605 with parameters: {'num_leaves': 23, 'max_depth': 12, 'learning_rate': 0.27688583700227487}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:06:24,938]\u001b[0m Finished trial#24 resulted in value: 0.6340482573726541. Current best value is 0.6613047363717605 with parameters: {'num_leaves': 23, 'max_depth': 12, 'learning_rate': 0.27688583700227487}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:06:38,316]\u001b[0m Finished trial#25 resulted in value: 0.6523681858802503. Current best value is 0.6613047363717605 with parameters: {'num_leaves': 23, 'max_depth': 12, 'learning_rate': 0.27688583700227487}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:06:52,429]\u001b[0m Finished trial#26 resulted in value: 0.5750670241286864. Current best value is 0.6613047363717605 with parameters: {'num_leaves': 23, 'max_depth': 12, 'learning_rate': 0.27688583700227487}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:07:03,670]\u001b[0m Finished trial#27 resulted in value: 0.6403038427167114. Current best value is 0.6613047363717605 with parameters: {'num_leaves': 23, 'max_depth': 12, 'learning_rate': 0.27688583700227487}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:07:16,681]\u001b[0m Finished trial#28 resulted in value: 0.6501340482573726. Current best value is 0.6613047363717605 with parameters: {'num_leaves': 23, 'max_depth': 12, 'learning_rate': 0.27688583700227487}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:07:30,761]\u001b[0m Finished trial#29 resulted in value: 0.3261840929401251. Current best value is 0.6613047363717605 with parameters: {'num_leaves': 23, 'max_depth': 12, 'learning_rate': 0.27688583700227487}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:07:44,046]\u001b[0m Finished trial#30 resulted in value: 0.6336014298480787. Current best value is 0.6613047363717605 with parameters: {'num_leaves': 23, 'max_depth': 12, 'learning_rate': 0.27688583700227487}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:07:54,564]\u001b[0m Finished trial#31 resulted in value: 0.5969615728328865. Current best value is 0.6613047363717605 with parameters: {'num_leaves': 23, 'max_depth': 12, 'learning_rate': 0.27688583700227487}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of outer_val_scores is  0.5713065755764304\n",
      "mean of test_scores is  0.5873333333333334\n",
      "outer_cv_4_processing....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-01 10:08:10,389]\u001b[0m Finished trial#0 resulted in value: 0.2597402597402597. Current best value is 0.2597402597402597 with parameters: {'num_leaves': 29, 'max_depth': 8, 'learning_rate': 3.3901348229746926e-08}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:08:24,931]\u001b[0m Finished trial#1 resulted in value: 0.2597402597402597. Current best value is 0.2597402597402597 with parameters: {'num_leaves': 29, 'max_depth': 8, 'learning_rate': 3.3901348229746926e-08}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:08:37,785]\u001b[0m Finished trial#2 resulted in value: 0.2597402597402597. Current best value is 0.2597402597402597 with parameters: {'num_leaves': 29, 'max_depth': 8, 'learning_rate': 3.3901348229746926e-08}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:08:47,067]\u001b[0m Finished trial#3 resulted in value: 0.2597402597402597. Current best value is 0.2597402597402597 with parameters: {'num_leaves': 29, 'max_depth': 8, 'learning_rate': 3.3901348229746926e-08}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:08:55,882]\u001b[0m Finished trial#4 resulted in value: 0.2597402597402597. Current best value is 0.2597402597402597 with parameters: {'num_leaves': 29, 'max_depth': 8, 'learning_rate': 3.3901348229746926e-08}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:09:08,796]\u001b[0m Finished trial#5 resulted in value: 0.6233766233766234. Current best value is 0.6233766233766234 with parameters: {'num_leaves': 26, 'max_depth': 15, 'learning_rate': 0.14532890515213867}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:09:23,768]\u001b[0m Finished trial#6 resulted in value: 0.5904761904761905. Current best value is 0.6233766233766234 with parameters: {'num_leaves': 26, 'max_depth': 15, 'learning_rate': 0.14532890515213867}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:09:36,802]\u001b[0m Finished trial#7 resulted in value: 0.2597402597402597. Current best value is 0.6233766233766234 with parameters: {'num_leaves': 26, 'max_depth': 15, 'learning_rate': 0.14532890515213867}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:09:48,414]\u001b[0m Finished trial#8 resulted in value: 0.2597402597402597. Current best value is 0.6233766233766234 with parameters: {'num_leaves': 26, 'max_depth': 15, 'learning_rate': 0.14532890515213867}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:10:02,342]\u001b[0m Finished trial#9 resulted in value: 0.2597402597402597. Current best value is 0.6233766233766234 with parameters: {'num_leaves': 26, 'max_depth': 15, 'learning_rate': 0.14532890515213867}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:10:13,967]\u001b[0m Finished trial#10 resulted in value: 0.6138528138528139. Current best value is 0.6233766233766234 with parameters: {'num_leaves': 26, 'max_depth': 15, 'learning_rate': 0.14532890515213867}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:10:24,694]\u001b[0m Finished trial#11 resulted in value: 0.6307359307359307. Current best value is 0.6307359307359307 with parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.19999460574595965}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:10:34,649]\u001b[0m Finished trial#12 resulted in value: 0.6264069264069264. Current best value is 0.6307359307359307 with parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.19999460574595965}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:10:43,978]\u001b[0m Finished trial#13 resulted in value: 0.49610389610389605. Current best value is 0.6307359307359307 with parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.19999460574595965}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:10:54,293]\u001b[0m Finished trial#14 resulted in value: 0.2597402597402597. Current best value is 0.6307359307359307 with parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.19999460574595965}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:11:04,155]\u001b[0m Finished trial#15 resulted in value: 0.6190476190476191. Current best value is 0.6307359307359307 with parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.19999460574595965}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:11:15,062]\u001b[0m Finished trial#16 resulted in value: 0.5813852813852813. Current best value is 0.6307359307359307 with parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.19999460574595965}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:11:27,286]\u001b[0m Finished trial#17 resulted in value: 0.5848484848484848. Current best value is 0.6307359307359307 with parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.19999460574595965}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:11:36,599]\u001b[0m Finished trial#18 resulted in value: 0.2597402597402597. Current best value is 0.6307359307359307 with parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.19999460574595965}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:11:47,852]\u001b[0m Finished trial#19 resulted in value: 0.5268398268398269. Current best value is 0.6307359307359307 with parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.19999460574595965}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:11:59,432]\u001b[0m Finished trial#20 resulted in value: 0.6268398268398269. Current best value is 0.6307359307359307 with parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.19999460574595965}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:12:10,921]\u001b[0m Finished trial#21 resulted in value: 0.6134199134199134. Current best value is 0.6307359307359307 with parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.19999460574595965}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:12:23,969]\u001b[0m Finished trial#22 resulted in value: 0.5956709956709957. Current best value is 0.6307359307359307 with parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.19999460574595965}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:12:34,435]\u001b[0m Finished trial#23 resulted in value: 0.5264069264069264. Current best value is 0.6307359307359307 with parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.19999460574595965}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:12:46,017]\u001b[0m Finished trial#24 resulted in value: 0.6038961038961039. Current best value is 0.6307359307359307 with parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.19999460574595965}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:12:55,642]\u001b[0m Finished trial#25 resulted in value: 0.6181818181818182. Current best value is 0.6307359307359307 with parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.19999460574595965}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:13:07,486]\u001b[0m Finished trial#26 resulted in value: 0.25497835497835497. Current best value is 0.6307359307359307 with parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.19999460574595965}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:13:18,097]\u001b[0m Finished trial#27 resulted in value: 0.2597402597402597. Current best value is 0.6307359307359307 with parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.19999460574595965}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:13:30,323]\u001b[0m Finished trial#28 resulted in value: 0.6264069264069264. Current best value is 0.6307359307359307 with parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.19999460574595965}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:13:45,123]\u001b[0m Finished trial#29 resulted in value: 0.6017316017316018. Current best value is 0.6307359307359307 with parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.19999460574595965}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:13:58,999]\u001b[0m Finished trial#30 resulted in value: 0.5935064935064935. Current best value is 0.6307359307359307 with parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.19999460574595965}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:14:10,812]\u001b[0m Finished trial#31 resulted in value: 0.6199134199134199. Current best value is 0.6307359307359307 with parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.19999460574595965}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of outer_val_scores is  0.651650312221231\n",
      "mean of test_scores is  0.6673333333333333\n",
      "outer_cv_5_processing....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-01 10:14:23,565]\u001b[0m Finished trial#0 resulted in value: 0.0. Current best value is 0.0 with parameters: {'num_leaves': 20, 'max_depth': 6, 'learning_rate': 0.0015637474960941695}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:14:33,426]\u001b[0m Finished trial#1 resulted in value: 0.0. Current best value is 0.0 with parameters: {'num_leaves': 20, 'max_depth': 6, 'learning_rate': 0.0015637474960941695}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:14:41,926]\u001b[0m Finished trial#2 resulted in value: 0.0. Current best value is 0.0 with parameters: {'num_leaves': 20, 'max_depth': 6, 'learning_rate': 0.0015637474960941695}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:14:53,437]\u001b[0m Finished trial#3 resulted in value: 0.0. Current best value is 0.0 with parameters: {'num_leaves': 20, 'max_depth': 6, 'learning_rate': 0.0015637474960941695}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:15:06,320]\u001b[0m Finished trial#4 resulted in value: 0.0. Current best value is 0.0 with parameters: {'num_leaves': 20, 'max_depth': 6, 'learning_rate': 0.0015637474960941695}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:15:17,644]\u001b[0m Finished trial#5 resulted in value: 0.0. Current best value is 0.0 with parameters: {'num_leaves': 20, 'max_depth': 6, 'learning_rate': 0.0015637474960941695}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:15:27,418]\u001b[0m Finished trial#6 resulted in value: 0.0. Current best value is 0.0 with parameters: {'num_leaves': 20, 'max_depth': 6, 'learning_rate': 0.0015637474960941695}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:15:42,418]\u001b[0m Finished trial#7 resulted in value: 0.5850234009360374. Current best value is 0.5850234009360374 with parameters: {'num_leaves': 33, 'max_depth': 9, 'learning_rate': 0.015392509935228102}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:15:55,722]\u001b[0m Finished trial#8 resulted in value: 0.05616224648985959. Current best value is 0.5850234009360374 with parameters: {'num_leaves': 33, 'max_depth': 9, 'learning_rate': 0.015392509935228102}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:16:07,785]\u001b[0m Finished trial#9 resulted in value: 0.6146645865834633. Current best value is 0.6146645865834633 with parameters: {'num_leaves': 23, 'max_depth': 8, 'learning_rate': 0.028867078212814878}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:16:17,484]\u001b[0m Finished trial#10 resulted in value: 0.62402496099844. Current best value is 0.62402496099844 with parameters: {'num_leaves': 16, 'max_depth': 11, 'learning_rate': 0.29484100904574456}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:16:26,718]\u001b[0m Finished trial#11 resulted in value: 0.6365054602184087. Current best value is 0.6365054602184087 with parameters: {'num_leaves': 16, 'max_depth': 11, 'learning_rate': 0.2789047035974217}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:16:35,484]\u001b[0m Finished trial#12 resulted in value: 0.6349453978159126. Current best value is 0.6365054602184087 with parameters: {'num_leaves': 16, 'max_depth': 11, 'learning_rate': 0.2789047035974217}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:16:45,015]\u001b[0m Finished trial#13 resulted in value: 0.62402496099844. Current best value is 0.6365054602184087 with parameters: {'num_leaves': 16, 'max_depth': 11, 'learning_rate': 0.2789047035974217}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:16:54,795]\u001b[0m Finished trial#14 resulted in value: 0.6396255850234009. Current best value is 0.6396255850234009 with parameters: {'num_leaves': 18, 'max_depth': 13, 'learning_rate': 0.25790259937001087}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:17:04,690]\u001b[0m Finished trial#15 resulted in value: 0.0. Current best value is 0.6396255850234009 with parameters: {'num_leaves': 18, 'max_depth': 13, 'learning_rate': 0.25790259937001087}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:17:14,957]\u001b[0m Finished trial#16 resulted in value: 0.4617784711388456. Current best value is 0.6396255850234009 with parameters: {'num_leaves': 18, 'max_depth': 13, 'learning_rate': 0.25790259937001087}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:17:25,607]\u001b[0m Finished trial#17 resulted in value: 0.625585023400936. Current best value is 0.6396255850234009 with parameters: {'num_leaves': 18, 'max_depth': 13, 'learning_rate': 0.25790259937001087}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:17:36,023]\u001b[0m Finished trial#18 resulted in value: 0.6302652106084243. Current best value is 0.6396255850234009 with parameters: {'num_leaves': 18, 'max_depth': 13, 'learning_rate': 0.25790259937001087}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:17:46,837]\u001b[0m Finished trial#19 resulted in value: 0.0. Current best value is 0.6396255850234009 with parameters: {'num_leaves': 18, 'max_depth': 13, 'learning_rate': 0.25790259937001087}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:17:56,744]\u001b[0m Finished trial#20 resulted in value: 0.0499219968798752. Current best value is 0.6396255850234009 with parameters: {'num_leaves': 18, 'max_depth': 13, 'learning_rate': 0.25790259937001087}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:18:05,827]\u001b[0m Finished trial#21 resulted in value: 0.6489859594383776. Current best value is 0.6489859594383776 with parameters: {'num_leaves': 15, 'max_depth': 11, 'learning_rate': 0.1618483079108459}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:18:14,788]\u001b[0m Finished trial#22 resulted in value: 0.6474258970358814. Current best value is 0.6489859594383776 with parameters: {'num_leaves': 15, 'max_depth': 11, 'learning_rate': 0.1618483079108459}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:18:24,461]\u001b[0m Finished trial#23 resulted in value: 0.6302652106084243. Current best value is 0.6489859594383776 with parameters: {'num_leaves': 15, 'max_depth': 11, 'learning_rate': 0.1618483079108459}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:18:34,606]\u001b[0m Finished trial#24 resulted in value: 0.38533541341653665. Current best value is 0.6489859594383776 with parameters: {'num_leaves': 15, 'max_depth': 11, 'learning_rate': 0.1618483079108459}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:18:45,654]\u001b[0m Finished trial#25 resulted in value: 0.6489859594383776. Current best value is 0.6489859594383776 with parameters: {'num_leaves': 15, 'max_depth': 11, 'learning_rate': 0.1618483079108459}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:18:57,719]\u001b[0m Finished trial#26 resulted in value: 0.0. Current best value is 0.6489859594383776 with parameters: {'num_leaves': 15, 'max_depth': 11, 'learning_rate': 0.1618483079108459}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:19:08,928]\u001b[0m Finished trial#27 resulted in value: 0.6521060842433697. Current best value is 0.6521060842433697 with parameters: {'num_leaves': 20, 'max_depth': 11, 'learning_rate': 0.08244668384502532}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:19:20,491]\u001b[0m Finished trial#28 resulted in value: 0.5959438377535101. Current best value is 0.6521060842433697 with parameters: {'num_leaves': 20, 'max_depth': 11, 'learning_rate': 0.08244668384502532}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:19:31,831]\u001b[0m Finished trial#29 resulted in value: 0.6427457098283932. Current best value is 0.6521060842433697 with parameters: {'num_leaves': 20, 'max_depth': 11, 'learning_rate': 0.08244668384502532}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:19:42,793]\u001b[0m Finished trial#30 resulted in value: 0.0. Current best value is 0.6521060842433697 with parameters: {'num_leaves': 20, 'max_depth': 11, 'learning_rate': 0.08244668384502532}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:19:53,749]\u001b[0m Finished trial#31 resulted in value: 0.6599063962558502. Current best value is 0.6599063962558502 with parameters: {'num_leaves': 20, 'max_depth': 11, 'learning_rate': 0.11606922776463931}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of outer_val_scores is  0.6018256900673766\n",
      "mean of test_scores is  0.6343333333333333\n",
      "outer_cv_6_processing....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-01 10:20:11,705]\u001b[0m Finished trial#0 resulted in value: 0.23534635879218474. Current best value is 0.23534635879218474 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.00197622170921235}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:20:23,292]\u001b[0m Finished trial#1 resulted in value: 0.23445825932504444. Current best value is 0.23534635879218474 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.00197622170921235}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:20:33,095]\u001b[0m Finished trial#2 resulted in value: 0.23445825932504444. Current best value is 0.23534635879218474 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.00197622170921235}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:20:46,296]\u001b[0m Finished trial#3 resulted in value: 0.23445825932504444. Current best value is 0.23534635879218474 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.00197622170921235}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:20:59,498]\u001b[0m Finished trial#4 resulted in value: 0.23445825932504444. Current best value is 0.23534635879218474 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.00197622170921235}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:21:09,458]\u001b[0m Finished trial#5 resulted in value: 0.23445825932504444. Current best value is 0.23534635879218474 with parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.00197622170921235}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:21:24,965]\u001b[0m Finished trial#6 resulted in value: 0.5550621669626998. Current best value is 0.5550621669626998 with parameters: {'num_leaves': 34, 'max_depth': 12, 'learning_rate': 0.004911519347859204}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:21:38,238]\u001b[0m Finished trial#7 resulted in value: 0.23445825932504444. Current best value is 0.5550621669626998 with parameters: {'num_leaves': 34, 'max_depth': 12, 'learning_rate': 0.004911519347859204}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:21:50,628]\u001b[0m Finished trial#8 resulted in value: 0.23445825932504444. Current best value is 0.5550621669626998 with parameters: {'num_leaves': 34, 'max_depth': 12, 'learning_rate': 0.004911519347859204}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:22:05,037]\u001b[0m Finished trial#9 resulted in value: 0.6598579040852576. Current best value is 0.6598579040852576 with parameters: {'num_leaves': 29, 'max_depth': 8, 'learning_rate': 0.033431951084947724}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:22:16,560]\u001b[0m Finished trial#10 resulted in value: 0.6909413854351687. Current best value is 0.6909413854351687 with parameters: {'num_leaves': 22, 'max_depth': 10, 'learning_rate': 0.23746318413735928}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:22:28,413]\u001b[0m Finished trial#11 resulted in value: 0.6953818827708703. Current best value is 0.6953818827708703 with parameters: {'num_leaves': 23, 'max_depth': 10, 'learning_rate': 0.18258388427987202}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:22:40,224]\u001b[0m Finished trial#12 resulted in value: 0.6953818827708703. Current best value is 0.6953818827708703 with parameters: {'num_leaves': 23, 'max_depth': 10, 'learning_rate': 0.18258388427987202}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:22:52,069]\u001b[0m Finished trial#13 resulted in value: 0.6980461811722913. Current best value is 0.6980461811722913 with parameters: {'num_leaves': 23, 'max_depth': 11, 'learning_rate': 0.19532932565935635}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:23:05,811]\u001b[0m Finished trial#14 resulted in value: 0.6403197158081705. Current best value is 0.6980461811722913 with parameters: {'num_leaves': 23, 'max_depth': 11, 'learning_rate': 0.19532932565935635}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:23:16,044]\u001b[0m Finished trial#15 resulted in value: 0.672291296625222. Current best value is 0.6980461811722913 with parameters: {'num_leaves': 23, 'max_depth': 11, 'learning_rate': 0.19532932565935635}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:23:28,543]\u001b[0m Finished trial#16 resulted in value: 0.23445825932504444. Current best value is 0.6980461811722913 with parameters: {'num_leaves': 23, 'max_depth': 11, 'learning_rate': 0.19532932565935635}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:23:40,555]\u001b[0m Finished trial#17 resulted in value: 0.6429840142095915. Current best value is 0.6980461811722913 with parameters: {'num_leaves': 23, 'max_depth': 11, 'learning_rate': 0.19532932565935635}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:23:50,496]\u001b[0m Finished trial#18 resulted in value: 0.672291296625222. Current best value is 0.6980461811722913 with parameters: {'num_leaves': 23, 'max_depth': 11, 'learning_rate': 0.19532932565935635}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:24:05,231]\u001b[0m Finished trial#19 resulted in value: 0.5310834813499112. Current best value is 0.6980461811722913 with parameters: {'num_leaves': 23, 'max_depth': 11, 'learning_rate': 0.19532932565935635}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:24:17,299]\u001b[0m Finished trial#20 resulted in value: 0.23445825932504444. Current best value is 0.6980461811722913 with parameters: {'num_leaves': 23, 'max_depth': 11, 'learning_rate': 0.19532932565935635}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:24:28,995]\u001b[0m Finished trial#21 resulted in value: 0.6918294849023091. Current best value is 0.6980461811722913 with parameters: {'num_leaves': 23, 'max_depth': 11, 'learning_rate': 0.19532932565935635}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:24:42,480]\u001b[0m Finished trial#22 resulted in value: 0.6802841918294849. Current best value is 0.6980461811722913 with parameters: {'num_leaves': 23, 'max_depth': 11, 'learning_rate': 0.19532932565935635}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:24:55,548]\u001b[0m Finished trial#23 resulted in value: 0.6163410301953819. Current best value is 0.6980461811722913 with parameters: {'num_leaves': 23, 'max_depth': 11, 'learning_rate': 0.19532932565935635}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:25:06,471]\u001b[0m Finished trial#24 resulted in value: 0.6838365896980462. Current best value is 0.6980461811722913 with parameters: {'num_leaves': 23, 'max_depth': 11, 'learning_rate': 0.19532932565935635}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:25:16,644]\u001b[0m Finished trial#25 resulted in value: 0.6669626998223801. Current best value is 0.6980461811722913 with parameters: {'num_leaves': 23, 'max_depth': 11, 'learning_rate': 0.19532932565935635}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:25:29,159]\u001b[0m Finished trial#26 resulted in value: 0.5861456483126111. Current best value is 0.6980461811722913 with parameters: {'num_leaves': 23, 'max_depth': 11, 'learning_rate': 0.19532932565935635}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:25:40,368]\u001b[0m Finished trial#27 resulted in value: 0.23090586145648312. Current best value is 0.6980461811722913 with parameters: {'num_leaves': 23, 'max_depth': 11, 'learning_rate': 0.19532932565935635}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:25:54,414]\u001b[0m Finished trial#28 resulted in value: 0.6785079928952042. Current best value is 0.6980461811722913 with parameters: {'num_leaves': 23, 'max_depth': 11, 'learning_rate': 0.19532932565935635}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:26:04,516]\u001b[0m Finished trial#29 resulted in value: 0.2291296625222025. Current best value is 0.6980461811722913 with parameters: {'num_leaves': 23, 'max_depth': 11, 'learning_rate': 0.19532932565935635}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:26:16,346]\u001b[0m Finished trial#30 resulted in value: 0.6873889875666075. Current best value is 0.6980461811722913 with parameters: {'num_leaves': 23, 'max_depth': 11, 'learning_rate': 0.19532932565935635}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:26:28,058]\u001b[0m Finished trial#31 resulted in value: 0.6900532859680284. Current best value is 0.6980461811722913 with parameters: {'num_leaves': 23, 'max_depth': 11, 'learning_rate': 0.19532932565935635}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of outer_val_scores is  0.6514439220953661\n",
      "mean of test_scores is  0.6613333333333333\n",
      "outer_cv_7_processing....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-01 10:26:39,723]\u001b[0m Finished trial#0 resulted in value: 0.14907651715039577. Current best value is 0.14907651715039577 with parameters: {'num_leaves': 15, 'max_depth': 6, 'learning_rate': 0.00012811336861543512}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:26:51,096]\u001b[0m Finished trial#1 resulted in value: 0.14907651715039577. Current best value is 0.14907651715039577 with parameters: {'num_leaves': 15, 'max_depth': 6, 'learning_rate': 0.00012811336861543512}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:27:01,017]\u001b[0m Finished trial#2 resulted in value: 0.14907651715039577. Current best value is 0.14907651715039577 with parameters: {'num_leaves': 15, 'max_depth': 6, 'learning_rate': 0.00012811336861543512}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:27:15,770]\u001b[0m Finished trial#3 resulted in value: 0.14907651715039577. Current best value is 0.14907651715039577 with parameters: {'num_leaves': 15, 'max_depth': 6, 'learning_rate': 0.00012811336861543512}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:27:27,162]\u001b[0m Finished trial#4 resulted in value: 0.14907651715039577. Current best value is 0.14907651715039577 with parameters: {'num_leaves': 15, 'max_depth': 6, 'learning_rate': 0.00012811336861543512}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:27:41,849]\u001b[0m Finished trial#5 resulted in value: 0.15963060686015831. Current best value is 0.15963060686015831 with parameters: {'num_leaves': 34, 'max_depth': 14, 'learning_rate': 0.001940112415935242}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:27:53,803]\u001b[0m Finished trial#6 resulted in value: 0.600263852242744. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:28:06,361]\u001b[0m Finished trial#7 resulted in value: 0.14907651715039577. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:28:19,079]\u001b[0m Finished trial#8 resulted in value: 0.14907651715039577. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:28:29,708]\u001b[0m Finished trial#9 resulted in value: 0.5864116094986808. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:28:40,095]\u001b[0m Finished trial#10 resulted in value: 0.5965259454705365. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:28:50,301]\u001b[0m Finished trial#11 resulted in value: 0.592788038698329. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:29:01,346]\u001b[0m Finished trial#12 resulted in value: 0.5507915567282322. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:29:11,121]\u001b[0m Finished trial#13 resulted in value: 0.49846086191732636. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:29:22,157]\u001b[0m Finished trial#14 resulted in value: 0.5965259454705365. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:29:34,777]\u001b[0m Finished trial#15 resulted in value: 0.14907651715039577. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:29:45,768]\u001b[0m Finished trial#16 resulted in value: 0.14973614775725594. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:29:59,725]\u001b[0m Finished trial#17 resulted in value: 0.5767370272647317. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:30:11,252]\u001b[0m Finished trial#18 resulted in value: 0.2726473175021988. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:30:24,713]\u001b[0m Finished trial#19 resulted in value: 0.5908091468777484. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:30:38,267]\u001b[0m Finished trial#20 resulted in value: 0.14907651715039577. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:30:47,800]\u001b[0m Finished trial#21 resulted in value: 0.5901495162708883. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:30:59,725]\u001b[0m Finished trial#22 resulted in value: 0.5903693931398417. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:31:12,271]\u001b[0m Finished trial#23 resulted in value: 0.5978452066842568. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:31:25,619]\u001b[0m Finished trial#24 resulted in value: 0.552990325417766. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:31:37,580]\u001b[0m Finished trial#25 resulted in value: 0.14907651715039577. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:31:49,670]\u001b[0m Finished trial#26 resulted in value: 0.5943271767810027. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:32:02,193]\u001b[0m Finished trial#27 resulted in value: 0.47339489885664027. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:32:16,204]\u001b[0m Finished trial#28 resulted in value: 0.14907651715039577. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:32:27,166]\u001b[0m Finished trial#29 resulted in value: 0.5503518029903254. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:32:38,407]\u001b[0m Finished trial#30 resulted in value: 0.5923482849604221. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:32:48,248]\u001b[0m Finished trial#31 resulted in value: 0.5901495162708883. Current best value is 0.600263852242744 with parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.1117768654554997}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of outer_val_scores is  0.5141104294478528\n",
      "mean of test_scores is  0.643\n",
      "outer_cv_8_processing....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-01 10:33:05,438]\u001b[0m Finished trial#0 resulted in value: 0.25756929637526654. Current best value is 0.25756929637526654 with parameters: {'num_leaves': 33, 'max_depth': 8, 'learning_rate': 9.018683107251851e-06}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:33:17,049]\u001b[0m Finished trial#1 resulted in value: 0.25756929637526654. Current best value is 0.25756929637526654 with parameters: {'num_leaves': 33, 'max_depth': 8, 'learning_rate': 9.018683107251851e-06}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:33:30,556]\u001b[0m Finished trial#2 resulted in value: 0.5816631130063966. Current best value is 0.5816631130063966 with parameters: {'num_leaves': 26, 'max_depth': 12, 'learning_rate': 0.01411973037708539}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:33:44,917]\u001b[0m Finished trial#3 resulted in value: 0.5428571428571428. Current best value is 0.5816631130063966 with parameters: {'num_leaves': 26, 'max_depth': 12, 'learning_rate': 0.01411973037708539}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:33:59,314]\u001b[0m Finished trial#4 resulted in value: 0.5211087420042644. Current best value is 0.5816631130063966 with parameters: {'num_leaves': 26, 'max_depth': 12, 'learning_rate': 0.01411973037708539}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:34:11,769]\u001b[0m Finished trial#5 resulted in value: 0.25756929637526654. Current best value is 0.5816631130063966 with parameters: {'num_leaves': 26, 'max_depth': 12, 'learning_rate': 0.01411973037708539}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:34:27,123]\u001b[0m Finished trial#6 resulted in value: 0.5970149253731343. Current best value is 0.5970149253731343 with parameters: {'num_leaves': 31, 'max_depth': 11, 'learning_rate': 0.0330088416905434}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:34:39,251]\u001b[0m Finished trial#7 resulted in value: 0.25756929637526654. Current best value is 0.5970149253731343 with parameters: {'num_leaves': 31, 'max_depth': 11, 'learning_rate': 0.0330088416905434}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:34:51,667]\u001b[0m Finished trial#8 resulted in value: 0.25756929637526654. Current best value is 0.5970149253731343 with parameters: {'num_leaves': 31, 'max_depth': 11, 'learning_rate': 0.0330088416905434}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:35:06,097]\u001b[0m Finished trial#9 resulted in value: 0.6277185501066098. Current best value is 0.6277185501066098 with parameters: {'num_leaves': 30, 'max_depth': 10, 'learning_rate': 0.09357744459034029}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:35:15,055]\u001b[0m Finished trial#10 resulted in value: 0.25756929637526654. Current best value is 0.6277185501066098 with parameters: {'num_leaves': 30, 'max_depth': 10, 'learning_rate': 0.09357744459034029}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:35:29,949]\u001b[0m Finished trial#11 resulted in value: 0.63454157782516. Current best value is 0.63454157782516 with parameters: {'num_leaves': 34, 'max_depth': 11, 'learning_rate': 0.1955206183410729}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:35:46,176]\u001b[0m Finished trial#12 resulted in value: 0.6251599147121535. Current best value is 0.63454157782516 with parameters: {'num_leaves': 34, 'max_depth': 11, 'learning_rate': 0.1955206183410729}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:36:01,081]\u001b[0m Finished trial#13 resulted in value: 0.6383795309168443. Current best value is 0.6383795309168443 with parameters: {'num_leaves': 35, 'max_depth': 10, 'learning_rate': 0.2677530081989092}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:36:16,470]\u001b[0m Finished trial#14 resulted in value: 0.6341151385927505. Current best value is 0.6383795309168443 with parameters: {'num_leaves': 35, 'max_depth': 10, 'learning_rate': 0.2677530081989092}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:36:26,071]\u001b[0m Finished trial#15 resulted in value: 0.6247334754797441. Current best value is 0.6383795309168443 with parameters: {'num_leaves': 35, 'max_depth': 10, 'learning_rate': 0.2677530081989092}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:36:37,457]\u001b[0m Finished trial#16 resulted in value: 0.25756929637526654. Current best value is 0.6383795309168443 with parameters: {'num_leaves': 35, 'max_depth': 10, 'learning_rate': 0.2677530081989092}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:36:51,955]\u001b[0m Finished trial#17 resulted in value: 0.25756929637526654. Current best value is 0.6383795309168443 with parameters: {'num_leaves': 35, 'max_depth': 10, 'learning_rate': 0.2677530081989092}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:37:06,447]\u001b[0m Finished trial#18 resulted in value: 0.25756929637526654. Current best value is 0.6383795309168443 with parameters: {'num_leaves': 35, 'max_depth': 10, 'learning_rate': 0.2677530081989092}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:37:19,671]\u001b[0m Finished trial#19 resulted in value: 0.25245202558635393. Current best value is 0.6383795309168443 with parameters: {'num_leaves': 35, 'max_depth': 10, 'learning_rate': 0.2677530081989092}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:37:33,971]\u001b[0m Finished trial#20 resulted in value: 0.25756929637526654. Current best value is 0.6383795309168443 with parameters: {'num_leaves': 35, 'max_depth': 10, 'learning_rate': 0.2677530081989092}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:37:49,196]\u001b[0m Finished trial#21 resulted in value: 0.6417910447761194. Current best value is 0.6417910447761194 with parameters: {'num_leaves': 35, 'max_depth': 12, 'learning_rate': 0.23701628596044308}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:38:05,813]\u001b[0m Finished trial#22 resulted in value: 0.6068230277185501. Current best value is 0.6417910447761194 with parameters: {'num_leaves': 35, 'max_depth': 12, 'learning_rate': 0.23701628596044308}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:38:20,619]\u001b[0m Finished trial#23 resulted in value: 0.6255863539445629. Current best value is 0.6417910447761194 with parameters: {'num_leaves': 35, 'max_depth': 12, 'learning_rate': 0.23701628596044308}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:38:36,163]\u001b[0m Finished trial#24 resulted in value: 0.5978678038379531. Current best value is 0.6417910447761194 with parameters: {'num_leaves': 35, 'max_depth': 12, 'learning_rate': 0.23701628596044308}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:38:51,438]\u001b[0m Finished trial#25 resulted in value: 0.6336886993603411. Current best value is 0.6417910447761194 with parameters: {'num_leaves': 35, 'max_depth': 12, 'learning_rate': 0.23701628596044308}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:39:05,394]\u001b[0m Finished trial#26 resulted in value: 0.6221748400852879. Current best value is 0.6417910447761194 with parameters: {'num_leaves': 35, 'max_depth': 12, 'learning_rate': 0.23701628596044308}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:39:16,581]\u001b[0m Finished trial#27 resulted in value: 0.4311300639658849. Current best value is 0.6417910447761194 with parameters: {'num_leaves': 35, 'max_depth': 12, 'learning_rate': 0.23701628596044308}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:39:31,906]\u001b[0m Finished trial#28 resulted in value: 0.5812366737739872. Current best value is 0.6417910447761194 with parameters: {'num_leaves': 35, 'max_depth': 12, 'learning_rate': 0.23701628596044308}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:39:46,395]\u001b[0m Finished trial#29 resulted in value: 0.6315565031982943. Current best value is 0.6417910447761194 with parameters: {'num_leaves': 35, 'max_depth': 12, 'learning_rate': 0.23701628596044308}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:40:01,599]\u001b[0m Finished trial#30 resulted in value: 0.6093816631130063. Current best value is 0.6417910447761194 with parameters: {'num_leaves': 35, 'max_depth': 12, 'learning_rate': 0.23701628596044308}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:40:16,692]\u001b[0m Finished trial#31 resulted in value: 0.6268656716417911. Current best value is 0.6417910447761194 with parameters: {'num_leaves': 35, 'max_depth': 12, 'learning_rate': 0.23701628596044308}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of outer_val_scores is  0.6865008880994672\n",
      "mean of test_scores is  0.6543333333333333\n",
      "outer_cv_9_processing....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-01 10:40:30,308]\u001b[0m Finished trial#0 resulted in value: 0.0. Current best value is 0.0 with parameters: {'num_leaves': 28, 'max_depth': 12, 'learning_rate': 4.717359237962781e-08}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:40:37,647]\u001b[0m Finished trial#1 resulted in value: 0.5147744945567652. Current best value is 0.5147744945567652 with parameters: {'num_leaves': 19, 'max_depth': 5, 'learning_rate': 0.019729732272038905}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:40:45,623]\u001b[0m Finished trial#2 resulted in value: 0.0. Current best value is 0.5147744945567652 with parameters: {'num_leaves': 19, 'max_depth': 5, 'learning_rate': 0.019729732272038905}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:40:53,043]\u001b[0m Finished trial#3 resulted in value: 0.0. Current best value is 0.5147744945567652 with parameters: {'num_leaves': 19, 'max_depth': 5, 'learning_rate': 0.019729732272038905}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:41:02,098]\u001b[0m Finished trial#4 resulted in value: 0.0. Current best value is 0.5147744945567652 with parameters: {'num_leaves': 19, 'max_depth': 5, 'learning_rate': 0.019729732272038905}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:41:09,311]\u001b[0m Finished trial#5 resulted in value: 0.0. Current best value is 0.5147744945567652 with parameters: {'num_leaves': 19, 'max_depth': 5, 'learning_rate': 0.019729732272038905}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:41:18,667]\u001b[0m Finished trial#6 resulted in value: 0.6656298600311042. Current best value is 0.6656298600311042 with parameters: {'num_leaves': 23, 'max_depth': 13, 'learning_rate': 0.11978745122173898}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:41:27,797]\u001b[0m Finished trial#7 resulted in value: 0.0. Current best value is 0.6656298600311042 with parameters: {'num_leaves': 23, 'max_depth': 13, 'learning_rate': 0.11978745122173898}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:41:37,125]\u001b[0m Finished trial#8 resulted in value: 0.0. Current best value is 0.6656298600311042 with parameters: {'num_leaves': 23, 'max_depth': 13, 'learning_rate': 0.11978745122173898}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:41:47,940]\u001b[0m Finished trial#9 resulted in value: 0.0. Current best value is 0.6656298600311042 with parameters: {'num_leaves': 23, 'max_depth': 13, 'learning_rate': 0.11978745122173898}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:42:00,638]\u001b[0m Finished trial#10 resulted in value: 0.6749611197511665. Current best value is 0.6749611197511665 with parameters: {'num_leaves': 35, 'max_depth': 13, 'learning_rate': 0.10799591649235986}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:42:12,353]\u001b[0m Finished trial#11 resulted in value: 0.656298600311042. Current best value is 0.6749611197511665 with parameters: {'num_leaves': 35, 'max_depth': 13, 'learning_rate': 0.10799591649235986}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:42:22,865]\u001b[0m Finished trial#12 resulted in value: 0.6734059097978227. Current best value is 0.6749611197511665 with parameters: {'num_leaves': 35, 'max_depth': 13, 'learning_rate': 0.10799591649235986}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:42:35,407]\u001b[0m Finished trial#13 resulted in value: 0.5505443234836703. Current best value is 0.6749611197511665 with parameters: {'num_leaves': 35, 'max_depth': 13, 'learning_rate': 0.10799591649235986}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:42:46,017]\u001b[0m Finished trial#14 resulted in value: 0.374805598755832. Current best value is 0.6749611197511665 with parameters: {'num_leaves': 35, 'max_depth': 13, 'learning_rate': 0.10799591649235986}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:42:57,268]\u001b[0m Finished trial#15 resulted in value: 0.6889580093312597. Current best value is 0.6889580093312597 with parameters: {'num_leaves': 35, 'max_depth': 8, 'learning_rate': 0.2931504915754598}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:43:08,510]\u001b[0m Finished trial#16 resulted in value: 0.656298600311042. Current best value is 0.6889580093312597 with parameters: {'num_leaves': 35, 'max_depth': 8, 'learning_rate': 0.2931504915754598}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:43:19,615]\u001b[0m Finished trial#17 resulted in value: 0.3312597200622084. Current best value is 0.6889580093312597 with parameters: {'num_leaves': 35, 'max_depth': 8, 'learning_rate': 0.2931504915754598}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:43:30,919]\u001b[0m Finished trial#18 resulted in value: 0.0. Current best value is 0.6889580093312597 with parameters: {'num_leaves': 35, 'max_depth': 8, 'learning_rate': 0.2931504915754598}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:43:41,584]\u001b[0m Finished trial#19 resulted in value: 0.6158631415241057. Current best value is 0.6889580093312597 with parameters: {'num_leaves': 35, 'max_depth': 8, 'learning_rate': 0.2931504915754598}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:43:52,951]\u001b[0m Finished trial#20 resulted in value: 0.02954898911353033. Current best value is 0.6889580093312597 with parameters: {'num_leaves': 35, 'max_depth': 8, 'learning_rate': 0.2931504915754598}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:44:02,916]\u001b[0m Finished trial#21 resulted in value: 0.6687402799377916. Current best value is 0.6889580093312597 with parameters: {'num_leaves': 35, 'max_depth': 8, 'learning_rate': 0.2931504915754598}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:44:13,510]\u001b[0m Finished trial#22 resulted in value: 0.6609642301710731. Current best value is 0.6889580093312597 with parameters: {'num_leaves': 35, 'max_depth': 8, 'learning_rate': 0.2931504915754598}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:44:24,424]\u001b[0m Finished trial#23 resulted in value: 0.6734059097978227. Current best value is 0.6889580093312597 with parameters: {'num_leaves': 35, 'max_depth': 8, 'learning_rate': 0.2931504915754598}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:44:36,255]\u001b[0m Finished trial#24 resulted in value: 0.38880248833592534. Current best value is 0.6889580093312597 with parameters: {'num_leaves': 35, 'max_depth': 8, 'learning_rate': 0.2931504915754598}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:44:43,677]\u001b[0m Finished trial#25 resulted in value: 0.640746500777605. Current best value is 0.6889580093312597 with parameters: {'num_leaves': 35, 'max_depth': 8, 'learning_rate': 0.2931504915754598}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:44:54,010]\u001b[0m Finished trial#26 resulted in value: 0.0. Current best value is 0.6889580093312597 with parameters: {'num_leaves': 35, 'max_depth': 8, 'learning_rate': 0.2931504915754598}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:45:05,274]\u001b[0m Finished trial#27 resulted in value: 0.6329704510108864. Current best value is 0.6889580093312597 with parameters: {'num_leaves': 35, 'max_depth': 8, 'learning_rate': 0.2931504915754598}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:45:17,008]\u001b[0m Finished trial#28 resulted in value: 0.2161741835147745. Current best value is 0.6889580093312597 with parameters: {'num_leaves': 35, 'max_depth': 8, 'learning_rate': 0.2931504915754598}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:45:27,549]\u001b[0m Finished trial#29 resulted in value: 0.5536547433903577. Current best value is 0.6889580093312597 with parameters: {'num_leaves': 35, 'max_depth': 8, 'learning_rate': 0.2931504915754598}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:45:38,742]\u001b[0m Finished trial#30 resulted in value: 0.0. Current best value is 0.6889580093312597 with parameters: {'num_leaves': 35, 'max_depth': 8, 'learning_rate': 0.2931504915754598}.\u001b[0m\n",
      "\u001b[32m[I 2020-12-01 10:45:49,815]\u001b[0m Finished trial#31 resulted in value: 0.6702954898911353. Current best value is 0.6889580093312597 with parameters: {'num_leaves': 35, 'max_depth': 8, 'learning_rate': 0.2931504915754598}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of outer_val_scores is  0.5667847349177331\n",
      "mean of test_scores is  0.6403333333333333\n"
     ]
    }
   ],
   "source": [
    "# train start -----------------------------------------------------------------------------\n",
    "train_start = datetime.datetime.now()\n",
    "\n",
    "for outer_cv in range(outer_cvs):\n",
    "    outer_start = datetime.datetime.now()\n",
    "    print(f'outer_cv_{outer_cv}_processing....')\n",
    "    # Data Loader-------------------------------------\n",
    "    train_files, val_files, X_outer_train, X_outer_val, Y_outer_train, Y_outer_val, val_train_region, val_train_point = lgb_splitter_cv(X_files, X_train, Y_train, outer_cv, region_train, train_point)\n",
    "    val_train_region = KMeans(n_clusters = outer_cvs, random_state=SEED).fit(val_train_point).labels_    \n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(opt_lgb, n_trials=n_trials)\n",
    "#     print(study.best_value)\n",
    "    \n",
    "    lgb_best_param = study.best_params\n",
    "    lgb_best = LGBMClassifier(**lgb_best_param)\n",
    "    lgb_best.fit(X_outer_train, Y_outer_train)\n",
    "    \n",
    "    print('mean of outer_val_scores is ', (np.array(lgb_best.predict(X_outer_val).astype(int) == Y_outer_val.astype(int)[0].values).sum() / len(Y_outer_val) ) )\n",
    "    print('mean of test_scores is ',      (np.array(lgb_best.predict(X_test).astype(int)      == Y_test.astype(int)[0].values).sum() / len(Y_test) ) )\n",
    "    #     print(lgb_best.predict_proba(X_outer_val).argmax(axis=1))\n",
    "    \n",
    "    try:\n",
    "        Y_val_files.append(val_files)\n",
    "    except:\n",
    "        Y_val_files =  [val_files]    \n",
    "    try:\n",
    "        lgb_scores.append(np.array(lgb_best.predict(X_outer_val).astype(int) == Y_outer_val.astype(int)[0].values).sum() / len(Y_outer_val))\n",
    "    except:\n",
    "        lgb_scores = [np.array(lgb_best.predict(X_outer_val).astype(int) == Y_outer_val.astype(int)[0].values).sum() / len(Y_outer_val)]\n",
    "    try:\n",
    "        lgb_best_params.append(lgb_best_param)\n",
    "    except:\n",
    "        lgb_best_params = [lgb_best_param]\n",
    "    try:\n",
    "        Y_val_smx.append(np.array(lgb_best.predict_proba(X_outer_val)))\n",
    "    except:\n",
    "        Y_val_smx = [np.array(lgb_best.predict_proba(X_outer_val))]\n",
    "    try:\n",
    "        Y_val_pred.append(lgb_best.predict(X_outer_val).astype(int))\n",
    "    except:\n",
    "        Y_val_pred = [lgb_best.predict(X_outer_val).astype(int)]\n",
    "    try:\n",
    "        Y_val_obs.append(Y_outer_val[0].values.astype(int))\n",
    "    except:\n",
    "        Y_val_obs =  [Y_outer_val[0].values.astype(int)]\n",
    "\n",
    "    outer_end = datetime.datetime.now()\n",
    "    spend_time = f\"Outer_cv time is {outer_end - outer_start} seconds.\"\n",
    "    pkl_saver(spend_time, os.path.join(time_path, f\"outer_cv_{outer_cv}_time.txt\"))\n",
    "\n",
    "train_end = datetime.datetime.now()\n",
    "spend_time = f\"Outer_cv time is {train_end - train_start} seconds.\"\n",
    "pkl_saver(spend_time, os.path.join(time_path, \"all_time.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./code/LULC_CNN_model.ipynb'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save Results -------------------------------------------------------------------------\n",
    "best_trial_num = np.argmax(lgb_scores)\n",
    "\n",
    "np.savetxt('Y_val_smx.txt', Y_val_smx[:][best_trial_num])\n",
    "param_names = lgb_best_params[list(map(len, lgb_best_params)).index(max(list(map(len, lgb_best_params))))].keys()\n",
    "best_params_dict = lgb_best_params[best_trial_num]\n",
    "pkl_saver(lgb_best_params, 'best_params_list.csv')\n",
    "pkl_saver(lgb_best_params, 'best_params.csv')\n",
    "best_params_dict = pkl_loader('best_params.csv')\n",
    "\n",
    "# Save CV_Result to csv -------------------------------------------------\n",
    "\n",
    "results = [Y_val_files[best_trial_num], Y_val_obs[best_trial_num], Y_val_pred[best_trial_num], Y_val_smx[:][best_trial_num]]\n",
    "pkl_saver(results, './results/results.pkl')\n",
    "make_df(val_files)\n",
    "results_csv = np.concatenate([make_df(Y_val_files[best_trial_num]),make_df(Y_val_obs[best_trial_num]), make_df(Y_val_pred[best_trial_num]), make_df(Y_val_smx[:][best_trial_num])], 1)\n",
    "results_csv = pd.DataFrame(results_csv)\n",
    "columns = [\"name\", \"obs\", \"pred\", 'Water', 'Urban and built-up', 'Rice paddy',  'Crops', 'Grassland', 'DBF', 'DNF', 'EBF', 'ENF', 'Bare land']\n",
    "results_csv.columns=columns\n",
    "results_csv.to_csv('./results/results_val.csv')\n",
    "labels = ['Water', 'Urban and built-up', 'Rice paddy',  'Crops', 'Grassland', 'DBF', 'DNF', 'EBF', 'ENF', 'Bare land']\n",
    "# cf_metr = confusion_matrix(Y_val_obs[best_trial_num].astype(int), Y_val_pred[best_trial_num])\n",
    "# cf_metr = pd.DataFrame(cf_metr)\n",
    "# cf_metr.columns=labels\n",
    "# cf_metr.index=labels\n",
    "# cf_metr.to_csv(\"./results/confusion_matrix_val.csv\")\n",
    "\n",
    "res_smr = classification_report(list(results_csv['obs'].astype(int)), list(results_csv['pred']), target_names = labels, labels = np.array(range(len(labels))))\n",
    "with open('./results/result_summary_val.txt','w') as f:\n",
    "    f.write(res_smr)\n",
    "\n",
    "# Best Model Training -----------------------------------------------\n",
    "best_model = LGBMClassifier(**lgb_best_params[best_trial_num])\n",
    "best_model.fit(X_train, Y_train)\n",
    "\n",
    "columns = [\"name\", \"obs\", \"pred\", 'Water', 'Urban and built-up', 'Rice paddy',  'Crops', 'Grassland', 'DBF', 'DNF', 'EBF', 'ENF', 'Bare land']\n",
    "results_csv.columns=columns\n",
    "results_csv.to_csv('./results/results_test.csv')\n",
    "labels = ['Water', 'Urban and built-up', 'Rice paddy',  'Crops', 'Grassland', 'DBF', 'DNF', 'EBF', 'ENF', 'Bare land']\n",
    "cf_metr = confusion_matrix(Y_test.astype(int).values, best_model.predict(X_test).astype(int))\n",
    "cf_metr = pd.DataFrame(cf_metr)\n",
    "cf_metr.columns=labels\n",
    "cf_metr.index=labels\n",
    "cf_metr.to_csv(\"./results/confusion_matrix_test.csv\")\n",
    "\n",
    "# ugokanaikamo \n",
    "LGB.plot_importance(best_model, height = 0.5, figsize = (8,16))\n",
    "plt.savefig('./figure.png')\n",
    "\n",
    "# Save Model -----------------------------------\n",
    "# best_model.save('./model/best_model.hdf5')\n",
    "# model_trained = True\n",
    "\n",
    "# Save Code\n",
    "import shutil\n",
    "os.mkdir(\"./code\")\n",
    "code_name = ipynb_path.get().split(\"/\")[-1]\n",
    "shutil.copy(ipynb_path.get(), f\"./code/{code_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.4\n"
     ]
    }
   ],
   "source": [
    "# Show Accuracy --------------------------------------------------------------------------\n",
    "acc = round(np.array(best_model.predict(X_test).astype(int) == Y_test.astype(int)[0].values).sum() / len(Y_test), 3)*100\n",
    "print(acc)\n",
    "pkl_saver(acc, f'acc_{acc}.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM + DEM data(1x1 pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Data Loader ------------------------------------------------------------------------\n",
    "N=1\n",
    "standarization = [\"normalization\", \"Zscore\", \"normal\", \"dem\"] # pklを作るまではCodeの書き換えも必要だよ！\n",
    "standarization_num= 3\n",
    "\n",
    "##### Data Loader ------------------------------\n",
    "if under==20:\n",
    "    train_tif_name = f\"D:/LULC/features/01_landsat8/train_old/{N}x{N}\"\n",
    "elif under==90:\n",
    "    train_tif_name = f\"D:/LULC/features/01_landsat8/train_new/{N}x{N}\"\n",
    "\n",
    "testfiles = glob(f\"D:/LULC/features/01_landsat8/train_new/{N}x{N}_test\" + \"/*.tif\")\n",
    "testfiles.sort()\n",
    "\n",
    "root_path      = f\"C:/Users/GE/Dropbox/Kairo/under{under}_results/\"\n",
    "result_path    = f\"C:/Users/GE/Dropbox/Kairo/under{under}_results/{N}x{N}\"\n",
    "data_path      = f\"C:/Users/GE/Dropbox/Kairo/under{under}_results/data/\"\n",
    "model_path     = f\"C:/Users/GE/Dropbox/Kairo/under{under}_results/model/{N}x{N}/\"\n",
    "imgfiles = glob(train_tif_name + \"/*.tif\")\n",
    "imgfiles.sort()\n",
    "train_dem_files = glob(os.path.join(f\"D:/LULC/features/01_landsat8/train_new/{N}x{N}_dem\", \"*\"))\n",
    "test_dem_files = glob(os.path.join(f\"D:/LULC/features/01_landsat8/train_new/{N}x{N}_test_dem\", \"*\"))\n",
    "train_dem_files.sort()\n",
    "test_dem_files.sort()\n",
    "model_trained = False\n",
    "\n",
    "# data import ---------------------------------------------------------------------------\n",
    "timename       = '{0:%Y_%m%d_%H%M}_dem'.format(datetime.datetime.now())\n",
    "time_path      =  os.path.join(result_path, lgb_boosting_type, timename, \"outer_cv_times\")\n",
    "make_dirs(lgb_boosting_type)\n",
    "\n",
    "X_files, X_train, Y_train, train_point, region_train = train_dem_import()\n",
    "X_train = X_train.astype(np.float64)\n",
    "Y_train = Y_train.astype(np.float64)\n",
    "\n",
    "Y_files, X_test, Y_test, test_point, region_test = test_dem_import()\n",
    "X_test = X_test.astype(np.float64)\n",
    "Y_test = Y_test.astype(np.float64) - 1\n",
    "\n",
    "\n",
    "# # Data converter ----------------------------------------------\n",
    "X_train = make_df(X_train)\n",
    "Y_train = make_df(Y_train)\n",
    "X_test =  make_df(X_test)\n",
    "Y_test = make_df(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import data_shape check --------------------------------------------------------\n",
    "print(\"X_train: \", type(X_train), X_train.shape)\n",
    "print(\"Y_train: \", type(Y_train), Y_train.shape)\n",
    "print(\"X_test: \", type(X_test), X_test.shape)\n",
    "print(\"Y_test: \", type(Y_test), Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del Y_val_files, lgb_scores, lgb_best_params,  Y_val_smx, Y_val_pred, Y_val_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# train start -----------------------------------------------------------------------------\n",
    "train_start = datetime.datetime.now()\n",
    "\n",
    "for outer_cv in range(outer_cvs):\n",
    "    outer_start = datetime.datetime.now()\n",
    "    print(f'outer_cv_{outer_cv}_processing....')\n",
    "    # Data Loader-------------------------------------\n",
    "    train_files, val_files, X_outer_train, X_outer_val, Y_outer_train, Y_outer_val, val_train_region, val_train_point = lgb_splitter_cv(X_files, X_train, Y_train, outer_cv, region_train, train_point)\n",
    "    val_train_region = KMeans(n_clusters = outer_cvs, random_state=SEED).fit(val_train_point).labels_    \n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(opt_lgb, n_trials=n_trials)\n",
    "#     print(study.best_value)\n",
    "    \n",
    "    lgb_best_param = study.best_params\n",
    "    lgb_best = LGBMClassifier(**lgb_best_param)\n",
    "    lgb_best.fit(X_outer_train, Y_outer_train)\n",
    "    \n",
    "    print('mean of outer_val_scores is ', (np.array(lgb_best.predict(X_outer_val).astype(int) == Y_outer_val.astype(int)[0].values).sum() / len(Y_outer_val) ) )\n",
    "    print('mean of test_scores is ',      (np.array(lgb_best.predict(X_test).astype(int)      == Y_test.astype(int)[0].values).sum() / len(Y_test) ) )\n",
    "    #     print(lgb_best.predict_proba(X_outer_val).argmax(axis=1))\n",
    "    \n",
    "    try:\n",
    "        Y_val_files.append(val_files)\n",
    "    except:\n",
    "        Y_val_files =  [val_files]    \n",
    "    try:\n",
    "        lgb_scores.append(np.array(lgb_best.predict(X_outer_val).astype(int) == Y_outer_val.astype(int)[0].values).sum() / len(Y_outer_val))\n",
    "    except:\n",
    "        lgb_scores = [np.array(lgb_best.predict(X_outer_val).astype(int) == Y_outer_val.astype(int)[0].values).sum() / len(Y_outer_val)]\n",
    "    try:\n",
    "        lgb_best_params.append(lgb_best_param)\n",
    "    except:\n",
    "        lgb_best_params = [lgb_best_param]\n",
    "    try:\n",
    "        Y_val_smx.append(np.array(lgb_best.predict_proba(X_outer_val)))\n",
    "    except:\n",
    "        Y_val_smx = [np.array(lgb_best.predict_proba(X_outer_val))]\n",
    "    try:\n",
    "        Y_val_pred.append(lgb_best.predict(X_outer_val).astype(int))\n",
    "    except:\n",
    "        Y_val_pred = [lgb_best.predict(X_outer_val).astype(int)]\n",
    "    try:\n",
    "        Y_val_obs.append(Y_outer_val[0].values.astype(int))\n",
    "    except:\n",
    "        Y_val_obs =  [Y_outer_val[0].values.astype(int)]\n",
    "\n",
    "    outer_end = datetime.datetime.now()\n",
    "    spend_time = f\"Outer_cv time is {outer_end - outer_start} seconds.\"\n",
    "    pkl_saver(spend_time, os.path.join(time_path, f\"outer_cv_{outer_cv}_time.txt\"))\n",
    "\n",
    "train_end = datetime.datetime.now()\n",
    "spend_time = f\"Outer_cv time is {train_end - train_start} seconds.\"\n",
    "pkl_saver(spend_time, os.path.join(time_path, \"all_time.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(lgb_best.predict(X_test).astype(int)), np.unique(Y_test.astype(int)[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save Results -------------------------------------------------------------------------\n",
    "best_trial_num = np.argmax(lgb_scores)\n",
    "\n",
    "np.savetxt('Y_val_smx.txt', Y_val_smx[:][best_trial_num])\n",
    "param_names = lgb_best_params[list(map(len, lgb_best_params)).index(max(list(map(len, lgb_best_params))))].keys()\n",
    "best_params_dict = lgb_best_params[best_trial_num]\n",
    "pkl_saver(lgb_best_params, 'best_params_list.csv')\n",
    "pkl_saver(lgb_best_params, 'best_params.csv')\n",
    "best_params_dict = pkl_loader('best_params.csv')\n",
    "\n",
    "# Save CV_Result to csv -------------------------------------------------\n",
    "\n",
    "results = [Y_val_files[best_trial_num], Y_val_obs[best_trial_num], Y_val_pred[best_trial_num], Y_val_smx[:][best_trial_num]]\n",
    "pkl_saver(results, './results/results.pkl')\n",
    "make_df(val_files)\n",
    "results_csv = np.concatenate([make_df(Y_val_files[best_trial_num]),make_df(Y_val_obs[best_trial_num]), make_df(Y_val_pred[best_trial_num]), make_df(Y_val_smx[:][best_trial_num])], 1)\n",
    "results_csv = pd.DataFrame(results_csv)\n",
    "columns = [\"name\", \"obs\", \"pred\", 'Water', 'Urban and built-up', 'Rice paddy',  'Crops', 'Grassland', 'DBF', 'DNF', 'EBF', 'ENF', 'Bare land']\n",
    "results_csv.columns=columns\n",
    "results_csv.to_csv('./results/results_val.csv')\n",
    "labels = ['Water', 'Urban and built-up', 'Rice paddy',  'Crops', 'Grassland', 'DBF', 'DNF', 'EBF', 'ENF', 'Bare land']\n",
    "# cf_metr = confusion_matrix(Y_val_obs[best_trial_num].astype(int), Y_val_pred[best_trial_num])\n",
    "# cf_metr = pd.DataFrame(cf_metr)\n",
    "# cf_metr.columns=labels\n",
    "# cf_metr.index=labels\n",
    "# cf_metr.to_csv(\"./results/confusion_matrix_val.csv\")\n",
    "\n",
    "res_smr = classification_report(list(results_csv['obs'].astype(int)), list(results_csv['pred']), target_names = labels, labels = np.array(range(len(labels))))\n",
    "with open('./results/result_summary_val.txt','w') as f:\n",
    "    f.write(res_smr)\n",
    "\n",
    "# Best Model Training -----------------------------------------------\n",
    "best_model = LGBMClassifier(**lgb_best_params[best_trial_num])\n",
    "best_model.fit(X_train, Y_train)\n",
    "\n",
    "columns = [\"name\", \"obs\", \"pred\", 'Water', 'Urban and built-up', 'Rice paddy',  'Crops', 'Grassland', 'DBF', 'DNF', 'EBF', 'ENF', 'Bare land']\n",
    "results_csv.columns=columns\n",
    "results_csv.to_csv('./results/results_test.csv')\n",
    "labels = ['Water', 'Urban and built-up', 'Rice paddy',  'Crops', 'Grassland', 'DBF', 'DNF', 'EBF', 'ENF', 'Bare land']\n",
    "cf_metr = confusion_matrix(Y_test.astype(int).values, best_model.predict(X_test).astype(int))\n",
    "cf_metr = pd.DataFrame(cf_metr)\n",
    "cf_metr.columns=labels\n",
    "cf_metr.index=labels\n",
    "cf_metr.to_csv(\"./results/confusion_matrix_test.csv\")\n",
    "\n",
    "# ugokanaikamo \n",
    "LGB.plot_importance(best_model, height = 0.5, figsize = (8,16))\n",
    "plt.savefig('./figure.png')\n",
    "\n",
    "# Save Model -----------------------------------\n",
    "# best_model.save('./model/best_model.hdf5')\n",
    "# model_trained = True\n",
    "\n",
    "# Save Code\n",
    "import shutil\n",
    "os.mkdir(\"./code\")\n",
    "code_name = ipynb_path.get().split(\"/\")[-1]\n",
    "shutil.copy(ipynb_path.get(), f\"./code/{code_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Show Accuracy --------------------------------------------------------------------------\n",
    "acc = round(np.array(best_model.predict(X_test).astype(int) == Y_test.astype(int)[0].values).sum() / len(Y_test), 3)*100\n",
    "print(acc)\n",
    "pkl_saver(acc, f'acc_{acc}.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM (3x3 pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Data Loader ------------------------------------------------------------------------\n",
    "N=3\n",
    "standarization = [\"normalization\", \"Zscore\", \"normal\"] # pklを作るまではCodeの書き換えも必要だよ！\n",
    "standarization_num= 2\n",
    "\n",
    "##### Data Loader ------------------------------\n",
    "if under==20:\n",
    "    train_tif_name = f\"D:/LULC/features/01_landsat8/train_old/{N}x{N}\"\n",
    "elif under==90:\n",
    "    train_tif_name = f\"D:/LULC/features/01_landsat8/train_new/{N}x{N}\"\n",
    "\n",
    "testfiles = glob(f\"D:/LULC/features/01_landsat8/train_new/{N}x{N}_test\" + \"/*.tif\")\n",
    "testfiles.sort()\n",
    "root_path      = f\"C:/Users/GE/Dropbox/Kairo/under{under}_results/\"\n",
    "result_path    = f\"C:/Users/GE/Dropbox/Kairo/under{under}_results/{N}x{N}\"\n",
    "data_path      = f\"C:/Users/GE/Dropbox/Kairo/under{under}_results/data/\"\n",
    "model_path     = f\"C:/Users/GE/Dropbox/Kairo/under{under}_results/model/{N}x{N}/\"\n",
    "imgfiles = glob(train_tif_name + \"/*.tif\")\n",
    "imgfiles.sort()\n",
    "model_trained = False\n",
    "\n",
    "# data import ---------------------------------------------------------------------------\n",
    "timename       = '{0:%Y_%m%d_%H%M}'.format(datetime.datetime.now())\n",
    "time_path      =  os.path.join(result_path, lgb_boosting_type, timename, \"outer_cv_times\")\n",
    "make_dirs(lgb_boosting_type)\n",
    "\n",
    "X_files, X_train, Y_train, train_point, region_train = train_import()\n",
    "X_train = X_train.astype(np.float64)\n",
    "\n",
    "if os.path.exists(data_path + f'df_{N}x{N}_{standarization[standarization_num]}.pkl'):\n",
    "    df_train = pkl_loader(data_path + f'df_{N}x{N}_{standarization[standarization_num]}.pkl')\n",
    "else:\n",
    "    X_train_zeros = np.zeros((X_train.shape[0], N*N*28))\n",
    "    for i in range(len(X_train)):\n",
    "        for k in range(3):\n",
    "            for l in range(3):\n",
    "                for j in range(28):\n",
    "                    X_train_zeros[i][j+k+l] = X_train[i][k][l][j]\n",
    "    X_train = X_train_zeros\n",
    "    df_train = pd.concat([make_df(Y_train), make_df(X_train)], axis=1)\n",
    "    pkl_saver(df_train, os.path.join(data_path, f'df_{N}x{N}_{standarization[standarization_num]}.pkl'))\n",
    "    \n",
    "\n",
    "Y_files, X_test, Y_test, test_point, region_test = test_import()\n",
    "X_test = X_test.astype(np.float64)\n",
    "if os.path.exists(data_path + f'df_{N}x{N}_test_{standarization[standarization_num]}.pkl'):\n",
    "    df_test = pkl_loader(data_path + f'df_{N}x{N}_test_{standarization[standarization_num]}.pkl')\n",
    "else:\n",
    "    X_test_zeros = np.zeros((X_test.shape[0], N*N*28))\n",
    "    for i in range(len(X_test)):\n",
    "        for k in range(3):\n",
    "            for l in range(3):\n",
    "                for j in range(28):\n",
    "                    X_test_zeros[i][j+k+l] = X_test[i][k][l][j]\n",
    "    X_test = X_test_zeros\n",
    "    df_test = pd.concat([make_df(Y_test), make_df(X_test)], axis=1)\n",
    "    pkl_saver(df_test, os.path.join(data_path, f'df_{N}x{N}_test_{standarization[standarization_num]}.pkl'))\n",
    "\n",
    "# Data converter ----------------------------------------------\n",
    "X_train = df_train.iloc[:, 1:]\n",
    "Y_train = make_df(Y_train)\n",
    "X_test =  df_test.iloc[:, 1:]\n",
    "Y_test = make_df(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del Y_val_files, lgb_scores, lgb_best_params,  Y_val_smx, Y_val_pred, Y_val_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# train start -----------------------------------------------------------------------------\n",
    "train_start = datetime.datetime.now()\n",
    "\n",
    "for outer_cv in range(outer_cvs):\n",
    "    outer_start = datetime.datetime.now()\n",
    "    print(f'outer_cv_{outer_cv}_processing....')\n",
    "    # Data Loader-------------------------------------\n",
    "    train_files, val_files, X_outer_train, X_outer_val, Y_outer_train, Y_outer_val, val_train_region, val_train_point = lgb_splitter_cv(X_files, X_train, Y_train, outer_cv, region_train, train_point)\n",
    "    val_train_region = KMeans(n_clusters = outer_cvs, random_state=SEED).fit(val_train_point).labels_\n",
    "    \n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(opt_lgb, n_trials=n_trials)\n",
    "#     print(study.best_value)\n",
    "    \n",
    "    lgb_best_param = study.best_params\n",
    "    lgb_best = LGBMClassifier(**lgb_best_param)\n",
    "    lgb_best.fit(X_outer_train, Y_outer_train)\n",
    "    \n",
    "    print('mean of outer_val_scores is ', (np.array(lgb_best.predict(X_outer_val).astype(int) == Y_outer_val.astype(int)[0].values).sum() / len(Y_outer_val) ) )\n",
    "    print('mean of test_scores is ',      (np.array((lgb_best.predict(X_test).astype(int)      == Y_test.astype(int)[0].values).sum() / len(Y_test) )) )\n",
    "    #     print(lgb_best.predict_proba(X_outer_val).argmax(axis=1))\n",
    "    \n",
    "    try:\n",
    "        Y_val_files.append(val_files)\n",
    "    except:\n",
    "        Y_val_files =  [val_files]    \n",
    "    try:\n",
    "        lgb_scores.append(np.array(lgb_best.predict(X_outer_val).astype(int) == Y_outer_val.astype(int)[0].values).sum() / len(Y_outer_val))\n",
    "    except:\n",
    "        lgb_scores = [np.array(lgb_best.predict(X_outer_val).astype(int) == Y_outer_val.astype(int)[0].values).sum() / len(Y_outer_val)]\n",
    "    try:\n",
    "        lgb_best_params.append(lgb_best_param)\n",
    "    except:\n",
    "        lgb_best_params = [lgb_best_param]\n",
    "    try:\n",
    "        Y_val_smx.append(np.array(lgb_best.predict_proba(X_outer_val)))\n",
    "    except:\n",
    "        Y_val_smx = [np.array(lgb_best.predict_proba(X_outer_val))]\n",
    "    try:\n",
    "        Y_val_pred.append(lgb_best.predict(X_outer_val).astype(int))\n",
    "    except:\n",
    "        Y_val_pred = [lgb_best.predict(X_outer_val).astype(int)]\n",
    "    try:\n",
    "        Y_val_obs.append(Y_outer_val[0].values.astype(int))\n",
    "    except:\n",
    "        Y_val_obs =  [Y_outer_val[0].values.astype(int)]\n",
    "\n",
    "    outer_end = datetime.datetime.now()\n",
    "    spend_time = f\"Outer_cv time is {outer_end - outer_start} seconds.\"\n",
    "    pkl_saver(spend_time, f\"./outer_cv_times/outer_cv_{outer_cv}_time.txt\")\n",
    "\n",
    "# Y_val_pred = [Y_val_pred[i:i+5454] for i in range(10)]\n",
    "# Y_val_smx = [Y_val_smx[i:i+5454] for i in range(10)\n",
    "train_end = datetime.datetime.now()\n",
    "spend_time = f\"Outer_cv time is {train_end - train_start} seconds.\"\n",
    "pkl_saver(spend_time, \"./outer_cv_times/all_time.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save Results -------------------------------------------------------------------------\n",
    "best_trial_num = np.argmax(lgb_scores)\n",
    "\n",
    "np.savetxt('Y_val_smx.txt', Y_val_smx[:][best_trial_num])\n",
    "param_names = lgb_best_params[list(map(len, lgb_best_params)).index(max(list(map(len, lgb_best_params))))].keys()\n",
    "best_params_dict = lgb_best_params[best_trial_num]\n",
    "pkl_saver(lgb_best_params, 'best_params_list.csv')\n",
    "pkl_saver(lgb_best_params, 'best_params.csv')\n",
    "best_params_dict = pkl_loader('best_params.csv')\n",
    "\n",
    "# Save CV_Result to csv -------------------------------------------------\n",
    "\n",
    "results = [Y_val_files[best_trial_num], Y_val_obs[best_trial_num], Y_val_pred[best_trial_num], Y_val_smx[:][best_trial_num]]\n",
    "pkl_saver(results, './results/results.pkl')\n",
    "make_df(val_files)\n",
    "results_csv = np.concatenate([make_df(Y_val_files[best_trial_num]),make_df(Y_val_obs[best_trial_num]), make_df(Y_val_pred[best_trial_num]), make_df(Y_val_smx[:][best_trial_num])], 1)\n",
    "results_csv = pd.DataFrame(results_csv)\n",
    "columns = [\"name\", \"obs\", \"pred\", 'Water', 'Urban and built-up', 'Rice paddy',  'Crops', 'Grassland', 'DBF', 'DNF', 'EBF', 'ENF', 'Bare land']\n",
    "results_csv.columns=columns\n",
    "results_csv.to_csv('./results/results_val.csv')\n",
    "labels = ['Water', 'Urban and built-up', 'Rice paddy',  'Crops', 'Grassland', 'DBF', 'DNF', 'EBF', 'ENF', 'Bare land']\n",
    "cf_metr = confusion_matrix(Y_val_obs[best_trial_num].astype(int), Y_val_pred[best_trial_num])\n",
    "cf_metr = pd.DataFrame(cf_metr)\n",
    "cf_metr.columns=labels\n",
    "cf_metr.index=labels\n",
    "cf_metr.to_csv(\"./results/confusion_matrix_val.csv\")\n",
    "\n",
    "res_smr = classification_report(list(results_csv['obs'].astype(int)), list(results_csv['pred']), target_names = labels, labels = np.array(range(len(labels))))\n",
    "with open('./results/result_summary_val.txt','w') as f:\n",
    "    f.write(res_smr)\n",
    "\n",
    "# Best Model Training -----------------------------------------------\n",
    "best_model = LGBMClassifier(**lgb_best_params[best_trial_num])\n",
    "best_model.fit(X_train, Y_train)\n",
    "\n",
    "columns = [\"name\", \"obs\", \"pred\", 'Water', 'Urban and built-up', 'Rice paddy',  'Crops', 'Grassland', 'DBF', 'DNF', 'EBF', 'ENF', 'Bare land']\n",
    "results_csv.columns=columns\n",
    "results_csv.to_csv('./results/results_test.csv')\n",
    "labels = ['Water', 'Urban and built-up', 'Rice paddy',  'Crops', 'Grassland', 'DBF', 'DNF', 'EBF', 'ENF', 'Bare land']\n",
    "cf_metr = confusion_matrix(Y_test.astype(int), best_model.predict(X_test).astype(int))\n",
    "cf_metr = pd.DataFrame(cf_metr)\n",
    "cf_metr.columns=labels\n",
    "cf_metr.index=labels\n",
    "cf_metr.to_csv(\"./results/confusion_matrix_test.csv\")\n",
    "\n",
    "# Save Model -----------------------------------\n",
    "# best_model.save('./model/best_model.hdf5')\n",
    "# model_trained = True\n",
    "\n",
    "# Save Code\n",
    "import shutil\n",
    "os.mkdir(\"./code\")\n",
    "code_name = ipynb_path.get().split(\"/\")[-1]\n",
    "shutil.copy(ipynb_path.get(), f\"./code/{code_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(best_model.predict(X_test).astype(int) == Y_test.astype(int)[0].values).sum() / len(Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "270.986px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
